{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710753929.131839       1 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.example_libraries import optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "from jax import vmap, pmap, jit, value_and_grad, local_device_count\n",
    "from jax.example_libraries import optimizers\n",
    "from jax.lax import scan, cond\n",
    "import pickle\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".75\" # needed because network is huge\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters of the SNN model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_initialization import args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Import the SHD dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DL size: 8156, Validation DL size: 1632, Test DL size: 2264\n"
     ]
    }
   ],
   "source": [
    "from utils_dataset import get_dataloader\n",
    "train_loader_custom_collate, val_loader_custom_collate, test_loader_custom_collate = get_dataloader( args=args, verbose=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Dataloader\n",
      "Mean Firing Rate on Test set: 0.1174876764294733\n",
      "Channels 0-100 Firing rate: 0.00706328125\n",
      "Channels 100-200 Firing rate: 0.010424175347222222\n",
      "Channels 200-300 Firing rate: 0.029488557449494954\n",
      "Channels 300-400 Firing rate: 0.08849810606060604\n",
      "Channels 400-500 Firing rate: 0.20145490451388887\n",
      "Channels 500-600 Firing rate: 0.29815841619318184\n",
      "Channels 600-700 Firing rate: 0.18732629419191915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippomoro/Documents/hsnn/spikin_datasets.py:75: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:620.)\n",
      "  x = torch.sparse.FloatTensor(x_idx, x_val, x_size).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bittar Dataloader\n",
      "Mean Firing Rate on Test set: 0.11748767644166946\n",
      "Channels 0-100 Firing rate: 0.00706328172236681\n",
      "Channels 100-200 Firing rate: 0.01042417623102665\n",
      "Channels 200-300 Firing rate: 0.02948855422437191\n",
      "Channels 300-400 Firing rate: 0.08849810808897018\n",
      "Channels 400-500 Firing rate: 0.20145492255687714\n",
      "Channels 500-600 Firing rate: 0.2981584072113037\n",
      "Channels 600-700 Firing rate: 0.18732629716396332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b17e47f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_spikes = []\n",
    "for step, (x, y) in enumerate(test_loader_custom_collate):\n",
    "    mean_spikes.append( x.mean(axis=(0,1)) )\n",
    "mean_activity = np.mean(mean_spikes, axis=0)\n",
    "# np.mean( mean_activity ), np.max(mean_activity), np.min(mean_activity), mean_activity.shape\n",
    "\n",
    "print('Our Dataloader')\n",
    "print(f'Mean Firing Rate on Test set: {np.mean( mean_activity )}')\n",
    "act_channels = []\n",
    "for i in range(7):\n",
    "    print( f'Channels {i*100}-{(i+1)*100} Firing rate: { np.mean( mean_activity[i*100:(i+1)*100] ) }' )\n",
    "    act_channels.append( np.mean( mean_activity[i*100:(i+1)*100] ) )\n",
    "\n",
    "\n",
    "# Loading dataloader from Bittar\n",
    "from spikin_datasets import load_shd_or_ssc\n",
    "test_loader_sparch = load_shd_or_ssc( \n",
    "    dataset_name = 'shd',\n",
    "    data_folder = '/Users/filippomoro/Desktop/KINGSTONE/Datasets/SHD/audiospikes',\n",
    "    split = 'test',\n",
    "    batch_size = 128,\n",
    "    nb_steps=100,\n",
    "    shuffle=False,\n",
    "    workers=0,\n",
    " )\n",
    "\n",
    "mean_spikes_bittar = []\n",
    "for step, (x, y) in enumerate(test_loader_sparch):\n",
    "    mean_spikes_bittar.append( x.mean(axis=(0,1)) )\n",
    "mean_activity_bittar = np.mean(mean_spikes_bittar, axis=0)\n",
    "# np.mean( mean_activity ), np.max(mean_activity), np.min(mean_activity), mean_activity.shape\n",
    "print('\\nBittar Dataloader')\n",
    "print(f'Mean Firing Rate on Test set: {np.mean( mean_activity_bittar )}')\n",
    "act_channels_bittar = []\n",
    "for i in range(7):\n",
    "    print( f'Channels {i*100}-{(i+1)*100} Firing rate: { np.mean( mean_activity_bittar[i*100:(i+1)*100] ) }' )\n",
    "    act_channels_bittar.append( np.mean( mean_activity_bittar[i*100:(i+1)*100] ) )\n",
    "\n",
    "fig, ax = plt.subplots( )\n",
    "ax.bar( np.arange(7), act_channels, alpha=0.75, width=0.25, label='OUR' )\n",
    "ax.bar( np.arange(7)+0.25, act_channels_bittar, alpha=0.75, width=0.25, label='Bittar' )\n",
    "ax.set_ylabel('Firing Rate [a.u.]', size=12)\n",
    "ax.set_xlabel('Channel-band [x100]', size=12)\n",
    "ax.legend(prop={'size':12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from spikin_datasets import SpikingDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils_dataset import custom_collate_fn\n",
    "\n",
    "# import dataset\n",
    "train_ds = SpikingDataset('shd', '/Users/filippomoro/Desktop/KINGSTONE/Datasets/SHD/audiospikes', 'train', args.nb_steps) # print(len(train_ds[0]))\n",
    "test_ds  = SpikingDataset('shd', '/Users/filippomoro/Desktop/KINGSTONE/Datasets/SHD/audiospikes', 'test', args.nb_steps) # print(len(train_ds[0]))\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "train_size = int(0.99 * len(train_ds))\n",
    "val_size   = len(train_ds) - train_size\n",
    "# train_ds_split = train_ds\n",
    "train_ds_split, val_ds_split = random_split(train_ds, [train_size, val_size])\n",
    "print(f'Train DL size: {len(train_ds)}, Validation DL size: {len(val_ds_split)}, Test DL size: {len(test_ds)}')\n",
    "\n",
    "train_loader_custom_collate = DataLoader(train_ds_split, args.batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader_custom_collate   = DataLoader(val_ds_split,   args.batch_size, shuffle=None, collate_fn=custom_collate_fn)\n",
    "test_loader_custom_collate  = DataLoader(test_ds,        args.batch_size, shuffle=None, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from utils_initialization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lif_step( args_in, input_spikes ):\n",
    "    ''' Forward function for the Leaky-Integrate and Fire neuron layer, adopted here for the hidden layers. '''\n",
    "    net_params, net_states = args_in\n",
    "    # state: the parameters (weights) and the state of the neurons (spikes, inputs and membrane, ecc..)\n",
    "    w, alpha = net_params; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states\n",
    "\n",
    "    # V_mem = (alpha) * (V_mem - out_spikes) + (1-alpha) * I_in #- out_spikes*v_thr\n",
    "    # V_mem = (alpha) * (V_mem - out_spikes) + I_in #- out_spikes*v_thr\n",
    "    V_mem = alpha * V_mem + input_spikes - out_spikes*v_thr\n",
    "    out_spikes = spiking_fn( V_mem, v_thr )\n",
    "    \n",
    "    return [ [w, alpha], [w_mask, tau, V_mem, out_spikes, v_thr, noise_sd] ], out_spikes\n",
    "\n",
    "\n",
    "# Leaky Integrate and Fire layer, Recurrent\n",
    "def rlif_step( args_in, input_spikes):\n",
    "    ''' Forward function for the Leaky-Integrate and Fire neuron layer, adopted here for the hidden layers. '''\n",
    "    net_params, net_states = args_in\n",
    "    # state: the parameters (weights) and the state of the neurons (spikes, inputs and membrane, ecc..)\n",
    "    w, alpha = net_params; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states\n",
    "    win_mask, wrec_mask = w_mask\n",
    "    if len(w) == 3: # it means that we'll do normalization\n",
    "        weight, scale, bias = w\n",
    "    else: weight = w\n",
    "    win, wrec = weight\n",
    "    w_rec_diag_zeros = jnp.ones_like(wrec) - jnp.eye( wrec.shape[0] )\n",
    "\n",
    "    # we evolve the state of the neuron according to the LIF formula, Euler approximation\n",
    "    I_rec = jnp.matmul(out_spikes, wrec*wrec_mask*w_rec_diag_zeros)\n",
    "    # V_mem = (alpha) * (V_mem) + (1-alpha) * I_in - out_spikes*v_thr\n",
    "    V_mem = alpha * V_mem + input_spikes + I_rec - out_spikes*v_thr\n",
    "    # V_mem = alpha * (V_mem - out_spikes) + (1-alpha) * ( I_in_norm )\n",
    "    # V_mem = alpha * (V_mem - out_spikes) + (1) * ( I_in_norm )\n",
    "    out_spikes = spiking_fn( V_mem, v_thr )\n",
    "    \n",
    "    return [ [w, alpha], [w_mask, tau, V_mem, out_spikes, v_thr, noise_sd] ], out_spikes\n",
    "\n",
    "# Leaky Integrator (output layer)\n",
    "def li_step(args_in, input_spikes):\n",
    "    ''' Forward function for the Leaky-Integrator neuron layer, adopted here for the output layers. '''\n",
    "    net_params, net_states = args_in\n",
    "    # state: the parameters (weights) and the state of the neurons (inputs and membrane)\n",
    "    w, alpha = net_params; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states\n",
    "\n",
    "    # we evolve the state of the neuron according to the LI formula, Euler approximation\n",
    "    V_mem = (alpha) * (V_mem) + (1-alpha) * input_spikes\n",
    "    # V_mem = (alpha) * (V_mem) + input_spikes\n",
    "    \n",
    "    return [ [w, alpha], [w_mask, tau, V_mem, out_spikes, v_thr, noise_sd] ], V_mem\n",
    "\n",
    "# parallelizing the Single Layer\n",
    "@jit\n",
    "def scan_layer( args_in, input_spikes ):\n",
    "    args_out_layer, out_spikes_layer = scan( layer, args_in, input_spikes, length=args.nb_steps )\n",
    "    return args_out_layer, out_spikes_layer\n",
    "vscan_layer = vmap( scan_layer, in_axes=(None, 0))\n",
    "\n",
    "@jit\n",
    "def scan_out_layer( args_in, input_spikes ):\n",
    "    args_out_layer, out_spikes_layer = scan( layer_out, args_in, input_spikes, length=args.nb_steps )\n",
    "    return args_out_layer, out_spikes_layer\n",
    "vscan_layer_out = vmap( scan_out_layer, in_axes=(None, 0))\n",
    "\n",
    "@jit\n",
    "def hsnn( args_in, input_spikes ):\n",
    "    net_params, net_states, key, dropout_rate = args_in\n",
    "    n_layers = len( net_params )\n",
    "    # collection of output spikes\n",
    "    out_spike_net = []\n",
    "    # Loop over the layers\n",
    "    for l in range(n_layers):\n",
    "        if l == 0: layer_input_spike = input_spikes\n",
    "        else: layer_input_spike = out_spikes_layer\n",
    "        # making layers' params and states explitic\n",
    "        # parameters (weights and alpha) and the state of the neurons (spikes, inputs and membrane, ecc..)\n",
    "        w, alpha = net_params[l]; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states[l]\n",
    "        if len(w) == 3: # it means that we'll do normalization\n",
    "            weight, scale, bias = w\n",
    "        else: weight = w\n",
    "        if len(weight) ==2: weight, _ = weight\n",
    "        # we evolve the state of the neuron according to the LIF formula, Euler approximation\n",
    "        I_in = jnp.matmul(layer_input_spike, weight)\n",
    "        # Normalization (if selected)\n",
    "        if len(w) == 3: # it means that we'll do normalization\n",
    "            b, t, n = I_in.shape\n",
    "            I_in = norm( I_in.reshape( b*t, n ), bias = bias, scale = scale )\n",
    "            I_in = I_in.reshape( b,t,n ) # normalized input current\n",
    "        # Forward pass of the Layer\n",
    "        args_in = [net_params[l], net_states[l]]\n",
    "        if l+1 == n_layers:\n",
    "            _, out_spikes_layer = vscan_layer_out( args_in, I_in )\n",
    "        else: \n",
    "            _, out_spikes_layer = vscan_layer( args_in, I_in )\n",
    "            # Dropout\n",
    "            key, key_dropout = jax.random.split(key, 2)\n",
    "            out_spikes_layer = dropout( key_dropout, out_spikes_layer, rate=dropout_rate, deterministic=False )\n",
    "        out_spike_net.append(out_spikes_layer)\n",
    "    return out_spikes_layer, out_spike_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( out_spikes_layer[0].T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( I_in[0].T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( out_spikes_vlayer[10].T )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization Layer debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from utils_initialization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization Layers\n",
    "from typing import (Any, Callable, Iterable, Optional, Tuple, Union)\n",
    "\n",
    "PRNGKey = Any\n",
    "Array = Any\n",
    "Shape = Tuple[int, ...]\n",
    "Dtype = Any  # this could be a real type?\n",
    "\n",
    "Axes = Union[int, Iterable[int]]\n",
    "\n",
    "def _canonicalize_axes(rank: int, axes: Axes) -> Tuple[int, ...]:\n",
    "    \"\"\"Returns a tuple of deduplicated, sorted, and positive axes.\"\"\"\n",
    "    if not isinstance(axes, Iterable):\n",
    "        axes = (axes,)\n",
    "    return tuple(set([rank + axis if axis < 0 else axis for axis in axes]))\n",
    "\n",
    "\n",
    "def _abs_sq(x):\n",
    "    \"\"\"Computes the elementwise square of the absolute value |x|^2.\"\"\"\n",
    "    if jnp.iscomplexobj(x):\n",
    "        return jax.lax.square(jax.lax.real(x)) + jax.lax.square(jax.lax.imag(x))\n",
    "    else:\n",
    "        return jax.lax.square(x)\n",
    "\n",
    "def _compute_stats(x: Array, axes: Axes,\n",
    "                   dtype: Optional[Dtype],\n",
    "                   axis_name: Optional[str] = None,\n",
    "                   axis_index_groups: Any = None):\n",
    "    \"\"\"Computes mean and variance statistics.\n",
    "    Returns:\n",
    "      A pair ``(mean, var)``.\n",
    "    \"\"\"\n",
    "    if dtype is None:\n",
    "      dtype = jnp.result_type(x)\n",
    "    # promote x to at least float32, this avoids half precision computation\n",
    "    # but preserves double or complex floating points\n",
    "    dtype = jnp.promote_types(dtype, jnp.float32)\n",
    "    x = jnp.asarray(x, dtype)\n",
    "\n",
    "    mean = jnp.mean(x, axes)\n",
    "    mean2 = jnp.mean(_abs_sq(x), axes)\n",
    "    if axis_name is not None:\n",
    "      concatenated_mean = jnp.concatenate([mean, mean2])\n",
    "      mean, mean2 = jnp.split(\n",
    "          jax.lax.pmean(\n",
    "              concatenated_mean,\n",
    "              axis_name=axis_name,\n",
    "              axis_index_groups=axis_index_groups), 2)\n",
    "    # mean2 - _abs_sq(mean) is not guaranteed to be non-negative due\n",
    "    # to floating point round-off errors.\n",
    "    var = jnp.maximum(0., mean2 - _abs_sq(mean))\n",
    "    return mean, var\n",
    "\n",
    "\n",
    "def _normalize(x: Array, mean: Array, var: Array,\n",
    "               reduction_axes: Axes, feature_axes: Axes,\n",
    "               dtype: Dtype, param_dtype: Dtype,\n",
    "               epsilon: float,\n",
    "               bias: Array,\n",
    "               scale: Array):\n",
    "    \"\"\"\"Normalizes the input of a normalization layer and optionally applies a learned scale and bias.\n",
    "\n",
    "    Arguments:\n",
    "    mdl: Module to apply the normalization in (normalization params will reside\n",
    "        in this module).\n",
    "    x: The input.\n",
    "    mean: Mean to use for normalization.\n",
    "    var: Variance to use for normalization.\n",
    "    reduction_axes: The axes in ``x`` to reduce.\n",
    "    feature_axes: Axes containing features. A separate bias and scale is learned\n",
    "        for each specified feature.\n",
    "    dtype: The dtype of the result (default: infer from input and params).\n",
    "    param_dtype: The dtype of the parameters.\n",
    "    epsilon: Normalization epsilon.\n",
    "    use_bias: If true, add a bias term to the output.\n",
    "    use_scale: If true, scale the output.\n",
    "    bias_init: Initialization function for the bias term.\n",
    "    scale_init: Initialization function for the scaling function.\n",
    "\n",
    "    Returns:\n",
    "    The normalized input.\n",
    "    \"\"\"\n",
    "    reduction_axes = _canonicalize_axes(x.ndim, reduction_axes)\n",
    "    feature_axes = _canonicalize_axes(x.ndim, feature_axes)\n",
    "    stats_shape = list(x.shape)\n",
    "    for axis in reduction_axes:\n",
    "        stats_shape[axis] = 1\n",
    "    mean = mean.reshape(stats_shape)\n",
    "    var = var.reshape(stats_shape)\n",
    "    feature_shape = [1] * x.ndim\n",
    "    reduced_feature_shape = []\n",
    "    for ax in feature_axes:\n",
    "        feature_shape[ax] = x.shape[ax]\n",
    "        reduced_feature_shape.append(x.shape[ax])\n",
    "    y = x - mean\n",
    "    mul = jax.lax.rsqrt(var + epsilon)\n",
    "    args = [x]\n",
    "    # scale = mdl.param('scale', scale_init, reduced_feature_shape,\n",
    "    #                     param_dtype).reshape(feature_shape)\n",
    "    mul *= scale\n",
    "    args.append(scale)\n",
    "    y *= mul\n",
    "    # bias = mdl.param('bias', bias_init, reduced_feature_shape,\n",
    "    #                     param_dtype).reshape(feature_shape)\n",
    "    y += bias\n",
    "    args.append(bias)\n",
    "    #   dtype = canonicalize_dtype(*args, dtype=dtype)\n",
    "    return jnp.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchNorm1d( x, epsilon: float = 1e-5, bias = jax.nn.initializers.zeros, scale = jax.nn.initializers.ones ):\n",
    "    mean, var = x.mean( axis=0 ), x.std( axis=0 )\n",
    "    return ( x - mean ) * jax.lax.rsqrt(var + epsilon) * scale + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4482066e-07 0.9999831\n",
      "1.4482066e-07 0.9999831\n",
      "[ 9.6857548e-08  5.3085387e-07 -2.7194619e-07 -1.5832484e-07] [0.9999738 0.9999815 0.9999896 0.9999858]\n",
      "[ 7.0780516e-08  5.2899122e-07 -2.6449561e-07 -1.5273690e-07] [0.9356177  1.0124657  0.91177166 0.9353869 ]\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "## NORMALIZATION ##\n",
    "###################\n",
    "from utils_normalization import *\n",
    "\n",
    "key = jax.random.PRNGKey(seed=args.seed)\n",
    "x = jax.random.normal( key, [128,4], dtype=jnp.float32 ) + 10\n",
    "mean, var = _compute_stats(x, axes=-1, dtype=jnp.float32)\n",
    "# print( mean, var )\n",
    "\n",
    "y = _normalize(x, mean, var,\n",
    "               reduction_axes = -1, feature_axes = -1,\n",
    "               dtype= jnp.float32, param_dtype = jnp.float32,\n",
    "               epsilon = 1e-6,\n",
    "               bias = jnp.zeros( (x.shape[-1]) ),\n",
    "               scale = jnp.ones( (x.shape[-1]) ))\n",
    "# print( jnp.mean(y, axis=-1), jnp.var(y, axis=-1) )\n",
    "print( jnp.mean(y), jnp.var(y) )\n",
    "\n",
    "ynorm = LayerNorm( x, bias = jnp.zeros( (x.shape[-1]) ),\n",
    "               scale = jnp.ones( (x.shape[-1]) ) )\n",
    "# print( jnp.mean(ynorm, axis=-1), jnp.var(ynorm, axis=-1) )\n",
    "print( jnp.mean(ynorm), jnp.var(ynorm) )\n",
    "\n",
    "yBnorm = BatchNorm( x, bias = jnp.zeros( (x.shape[-1]) ),\n",
    "               scale = jnp.ones( (x.shape[-1]) ) )\n",
    "# print( jnp.mean(yBnorm), jnp.var(yBnorm) )\n",
    "print( jnp.mean(yBnorm, axis=0), jnp.var(yBnorm, axis=0) )\n",
    "\n",
    "yBnorm1d = BatchNorm1d( x, bias = jnp.zeros( (x.shape[-1]) ),\n",
    "               scale = jnp.ones( (x.shape[-1]) ) )\n",
    "# print( jnp.mean(yBnorm), jnp.var(yBnorm) )\n",
    "print( jnp.mean(yBnorm1d, axis=0), jnp.var(yBnorm1d, axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.0058588e-07 -9.6578151e-07  1.0244548e-08  7.9604797e-07] [1.0000117  1.0000201  0.99998796 0.9999766 ]\n",
      "0.99999905\n",
      "[0.5000058  0.5000101  0.49999398 0.49998817]\n",
      "[-2.5029294e-07 -4.8289075e-07  5.1222742e-09  3.9802399e-07]\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(seed=args.seed)\n",
    "x = jax.random.normal( key, [1024,4], dtype=jnp.float32 ) + 10\n",
    "\n",
    "yBnorm1d = BatchNorm( x, bias = jnp.zeros( (x.shape[-1]) ),\n",
    "               scale = jnp.ones( (x.shape[-1]) ) )\n",
    "# print( jnp.mean(yBnorm), jnp.var(yBnorm) )\n",
    "print( jnp.mean(yBnorm1d, axis=0), jnp.var(yBnorm1d, axis=0) )\n",
    "\n",
    "def loss_bn_jax(x, params):\n",
    "    scale, bias = params\n",
    "    yBnorm1d = BatchNorm( x, bias = bias, scale = scale )\n",
    "    return jnp.square(yBnorm1d).mean()\n",
    "\n",
    "params = [ jnp.ones( (x.shape[-1]), dtype=jnp.float32 ), jnp.zeros( (x.shape[-1]), dtype=jnp.float32 ) ]\n",
    "value, grads = value_and_grad(loss_bn_jax, has_aux=False, argnums=(1))(x, params)\n",
    "print( value )\n",
    "print( grads[0] )\n",
    "print( grads[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.8685e-07,  7.3016e-07, -7.6368e-07, -1.9372e-07],\n",
      "       grad_fn=<MeanBackward1>) tensor([1.0010, 1.0010, 1.0010, 1.0010], grad_fn=<VarBackward0>)\n",
      "tensor([0.5000, 0.5000, 0.5000, 0.5000])\n",
      "tensor([-1.4482e-07,  3.6252e-07, -3.8208e-07, -9.7789e-08])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "xtorch = torch.from_numpy( np.array(x) ).type(torch.float32)\n",
    "\n",
    "BN = torch.nn.BatchNorm1d( num_features=x.shape[1], track_running_stats=False, dtype=torch.float32 )\n",
    "yBnorm_torch = BN( xtorch )\n",
    "print( torch.mean(yBnorm_torch, axis=(0)), torch.var(yBnorm_torch, axis=0) )\n",
    "\n",
    "loss_bn_torch = torch.square(yBnorm_torch).mean()\n",
    "loss_bn_torch.backward()\n",
    "\n",
    "print( BN.weight.grad )\n",
    "print( BN.bias.grad )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug of the neuron model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lif_step( args_in, input_spikes ):\n",
    "    ''' Forward function for the Leaky-Integrate and Fire neuron layer, adopted here for the hidden layers. '''\n",
    "    net_params, net_states = args_in\n",
    "    # state: the parameters (weights) and the state of the neurons (spikes, inputs and membrane, ecc..)\n",
    "    w, alpha = net_params; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states\n",
    "\n",
    "    # V_mem = (alpha) * (V_mem - out_spikes) + (1-alpha) * I_in #- out_spikes*v_thr\n",
    "    # V_mem = (alpha) * (V_mem - out_spikes) + I_in #- out_spikes*v_thr\n",
    "    V_mem = alpha * V_mem + input_spikes - out_spikes*v_thr\n",
    "    out_spikes = spiking_fn( V_mem, v_thr )\n",
    "    \n",
    "    return [ [w, alpha], [w_mask, tau, V_mem, out_spikes, v_thr, noise_sd] ], out_spikes\n",
    "\n",
    "\n",
    "# Leaky Integrate and Fire layer, Recurrent\n",
    "def rlif_step( args_in, input_spikes):\n",
    "    ''' Forward function for the Leaky-Integrate and Fire neuron layer, adopted here for the hidden layers. '''\n",
    "    net_params, net_states = args_in\n",
    "    # state: the parameters (weights) and the state of the neurons (spikes, inputs and membrane, ecc..)\n",
    "    w, alpha = net_params; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states\n",
    "    win_mask, wrec_mask = w_mask\n",
    "    if len(w) == 3: # it means that we'll do normalization\n",
    "        weight, scale, bias = w\n",
    "    else: weight = w\n",
    "    win, wrec = weight\n",
    "    w_rec_diag_zeros = jnp.ones_like(wrec) - jnp.eye( wrec.shape[0] )\n",
    "\n",
    "    # we evolve the state of the neuron according to the LIF formula, Euler approximation\n",
    "    I_rec = jnp.matmul(out_spikes, wrec*wrec_mask*w_rec_diag_zeros)\n",
    "    # V_mem = (alpha) * (V_mem) + (1-alpha) * I_in - out_spikes*v_thr\n",
    "    V_mem = alpha * V_mem + input_spikes + I_rec - out_spikes*v_thr\n",
    "    # V_mem = alpha * (V_mem - out_spikes) + (1-alpha) * ( I_in_norm )\n",
    "    # V_mem = alpha * (V_mem - out_spikes) + (1) * ( I_in_norm )\n",
    "    out_spikes = spiking_fn( V_mem, v_thr )\n",
    "    \n",
    "    return [ [w, alpha], [w_mask, tau, V_mem, out_spikes, v_thr, noise_sd] ], out_spikes\n",
    "\n",
    "# Leaky Integrator (output layer)\n",
    "def li_step(args_in, input_spikes):\n",
    "    ''' Forward function for the Leaky-Integrator neuron layer, adopted here for the output layers. '''\n",
    "    net_params, net_states = args_in\n",
    "    # state: the parameters (weights) and the state of the neurons (inputs and membrane)\n",
    "    w, alpha = net_params; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states\n",
    "\n",
    "    # we evolve the state of the neuron according to the LI formula, Euler approximation\n",
    "    V_mem = (alpha) * (V_mem) + (1-alpha) * input_spikes\n",
    "    # V_mem = (alpha) * (V_mem) + input_spikes\n",
    "    \n",
    "    return [ [w, alpha], [w_mask, tau, V_mem, out_spikes, v_thr, noise_sd] ], V_mem\n",
    "\n",
    "# parallelizing the Single Layer\n",
    "@jit\n",
    "def scan_layer( args_in, input_spikes ):\n",
    "    args_out_layer, out_spikes_layer = scan( layer, args_in, input_spikes, length=args.nb_steps )\n",
    "    return args_out_layer, out_spikes_layer\n",
    "vscan_layer = vmap( scan_layer, in_axes=(None, 0))\n",
    "\n",
    "@jit\n",
    "def scan_out_layer( args_in, input_spikes ):\n",
    "    args_out_layer, out_spikes_layer = scan( layer_out, args_in, input_spikes, length=args.nb_steps )\n",
    "    return args_out_layer, out_spikes_layer\n",
    "vscan_layer_out = vmap( scan_out_layer, in_axes=(None, 0))\n",
    "\n",
    "@jit\n",
    "def hsnn( args_in, input_spikes ):\n",
    "    net_params, net_states, key, dropout_rate = args_in\n",
    "    n_layers = len( net_params )\n",
    "    # collection of output spikes\n",
    "    out_spike_net = []\n",
    "    # Loop over the layers\n",
    "    for l in range(n_layers):\n",
    "        if l == 0: layer_input_spike = input_spikes\n",
    "        else: layer_input_spike = out_spikes_layer\n",
    "        # making layers' params and states explitic\n",
    "        # parameters (weights and alpha) and the state of the neurons (spikes, inputs and membrane, ecc..)\n",
    "        w, alpha = net_params[l]; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states[l]\n",
    "        if len(w) == 3: # it means that we'll do normalization\n",
    "            weight, scale, bias = w\n",
    "        else: weight = w\n",
    "        if len(weight) ==2: weight, _ = weight\n",
    "        # we evolve the state of the neuron according to the LIF formula, Euler approximation\n",
    "        I_in = jnp.matmul(layer_input_spike, weight)\n",
    "        # Normalization (if selected)\n",
    "        if len(w) == 3: # it means that we'll do normalization\n",
    "            b, t, n = I_in.shape\n",
    "            I_in = norm( I_in.reshape( b*t, n ), bias = bias, scale = scale )\n",
    "            I_in = I_in.reshape( b,t,n ) # normalized input current\n",
    "        # Forward pass of the Layer\n",
    "        args_in_layer = [net_params[l], net_states[l]]\n",
    "        if l+1 == n_layers:\n",
    "            _, out_spikes_layer = vscan_layer_out( args_in_layer, I_in )\n",
    "        else: \n",
    "            _, out_spikes_layer = vscan_layer( args_in_layer, I_in )\n",
    "            # Dropout\n",
    "            key, key_dropout = jax.random.split(key, 2)\n",
    "            out_spikes_layer = dropout( key_dropout, out_spikes_layer, rate=dropout_rate, deterministic=False )\n",
    "        out_spike_net.append(out_spikes_layer)\n",
    "    return out_spikes_layer, out_spike_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def hsnn( args_in, input_spikes ):\n",
    "    net_params, net_states, key, dropout_rate = args_in\n",
    "    n_layers = len( net_params )\n",
    "    # collection of output spikes\n",
    "    out_spike_net = []\n",
    "    # Loop over the layers\n",
    "    for l in range(n_layers):\n",
    "        if l == 0: layer_input_spike = input_spikes\n",
    "        else: layer_input_spike = out_spikes_layer\n",
    "        # making layers' params and states explitic\n",
    "        # parameters (weights and alpha) and the state of the neurons (spikes, inputs and membrane, ecc..)\n",
    "        w, alpha = net_params[l]; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states[l]\n",
    "        if len(w) == 3: # it means that we'll do normalization\n",
    "            weight, scale, bias = w\n",
    "        else: weight = w\n",
    "        if len(weight) ==2: weight, _ = weight\n",
    "        # we evolve the state of the neuron according to the LIF formula, Euler approximation\n",
    "        I_in = jnp.matmul(layer_input_spike, weight)\n",
    "        # Normalization (if selected)\n",
    "        if len(w) == 3: # it means that we'll do normalization\n",
    "            b, t, n = I_in.shape\n",
    "            I_in = norm( I_in.reshape( b*t, n ), bias = bias, scale = scale )\n",
    "            I_in = I_in.reshape( b,t,n ) # normalized input current\n",
    "        # Forward pass of the Layer\n",
    "        args_in_layer = [net_params[l], net_states[l]]\n",
    "        if l+1 == n_layers:\n",
    "            _, out_spikes_layer = vscan_layer_out( args_in_layer, I_in )\n",
    "        else: \n",
    "            _, out_spikes_layer = vscan_layer( args_in_layer, I_in )\n",
    "            # Dropout\n",
    "            key, key_dropout = jax.random.split(key, 2)\n",
    "            out_spikes_layer = dropout( key_dropout, out_spikes_layer, rate=dropout_rate, deterministic=False )\n",
    "        out_spike_net.append(out_spikes_layer)\n",
    "    return out_spikes_layer, out_spike_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def scan_layer( args_in, input_spikes ):\n",
    "    args_out_layer, out_spikes_layer = scan( layer, args_in, input_spikes, length=args.nb_steps )\n",
    "    return args_out_layer, out_spikes_layer\n",
    "vscan_layer = vmap( scan_layer, in_axes=(None, 0))\n",
    "\n",
    "@jit\n",
    "def scan_out_layer( args_in, input_spikes ):\n",
    "    args_out_layer, out_spikes_layer = scan( layer_out, args_in, input_spikes, length=args.nb_steps )\n",
    "    return args_out_layer, out_spikes_layer\n",
    "vscan_layer_out = vmap( scan_out_layer, in_axes=(None, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: train (128, 100, 700) - test (128, 100, 700)\n"
     ]
    }
   ],
   "source": [
    "### try and do a forward pass\n",
    "key = jax.random.PRNGKey(seed=args.seed)\n",
    "# load data\n",
    "x_train, Y = next(iter( train_loader_custom_collate ))\n",
    "x_test, Y_test = next(iter( train_loader_custom_collate ))\n",
    "print('Input shape: train '+ str(x_train.shape) + ' - test '+ str(x_test.shape) )\n",
    "\n",
    "# initialize parameters\n",
    "dropout_rate = 0.0\n",
    "args.distrib_tau = True\n",
    "args.hierarchy_tau = True\n",
    "args.recurrent = False\n",
    "args.normalizer = 'batch' #'layer'\n",
    "args.norm_bias_init = 0.\n",
    "args.n_layers = 4\n",
    "if args.recurrent:\n",
    "    layer = rlif_step\n",
    "    # model = hrsnn\n",
    "else:\n",
    "    layer = lif_step\n",
    "    # model = hsnn\n",
    "layer_out = lif_step\n",
    "norm = BatchNorm\n",
    "args.w_scale = [0.3]\n",
    "net_params, net_states = params_initializer( key, args )\n",
    "\n",
    "###################################################################################################\n",
    "#################################      EVOLUTION OF THE LAYER     #################################\n",
    "###################################################################################################\n",
    "input_spikes = x_test\n",
    "# state: the parameters (weights) and the state of the neurons (spikes, inputs and membrane, ecc..)\n",
    "w, alpha = net_params[0]; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states[0]\n",
    "if len(w) == 3: # it means that we'll do normalization\n",
    "    weight, scale, bias = w\n",
    "else: weight = w\n",
    "if len(weight) == 2: weight, _ = weight\n",
    "\n",
    "# we evolve the state of the neuron according to the LIF formula, Euler approximation\n",
    "I_in = jnp.matmul(input_spikes, weight)\n",
    "# normalize inputs\n",
    "if len(w) == 3: \n",
    "    b, t, n = I_in.shape\n",
    "    I_in = norm( I_in.reshape( b*t, n ), bias = bias, scale = scale )\n",
    "    I_in = I_in.reshape( b,t,n )\n",
    "else: I_in = I_in\n",
    "\n",
    "# Single step\n",
    "args_in = [net_params[0], net_states[0]]\n",
    "args_out_step, out_spikes_step = layer( args_in, I_in[0,0] )\n",
    "\n",
    "# Single Layer\n",
    "args_in = [net_params[0], net_states[0]]\n",
    "args_out_layer, out_spikes_layer = scan( layer, args_in, I_in[0], length=args.nb_steps )\n",
    "\n",
    "# parallelizing the Single Layer\n",
    "@jit\n",
    "def scan_layer( args_in, input_spikes ):\n",
    "    args_out_layer, out_spikes_layer = scan( layer, args_in, input_spikes, length=args.nb_steps )\n",
    "    return args_out_layer, out_spikes_layer\n",
    "args_in = [net_params[0], net_states[0]]\n",
    "vscan_layer = vmap( scan_layer, in_axes=(None, 0))\n",
    "args_out_vlayer, out_spikes_vlayer = vscan_layer( args_in, I_in )\n",
    "\n",
    "# Forward pass throught the whole model\n",
    "args_in = [net_params, net_states, key, dropout_rate]\n",
    "out_spikes_layer, out_spike_net = hsnn( args_in, input_spikes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2fc728160>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAG6CAYAAADnOSfBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEv0lEQVR4nO3de1wWZf7/8fcNAnImUVLLQMyzpVtsaerXU+oaplhbaoqipVnrZmq66bdCK1NbT+lumgfCwko87marmOspzbQ0zVYtc9E1XTzL7YmTzO8Pv9w/b0EEvGG4mdfz8bgfj+5rrpn5XBd4825m7hmbYRiGAAAALMLD7AIAAADKEuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYSiWzCyhvcnNzdfz4cQUGBspms5ldDgAAKALDMHThwgXVrFlTHh6FH9sh/Nzg+PHjqlWrltllAACAEjh69KjuvvvuQvsQfm4QGBgo6drkBQUFmVwNAAAoCrvdrlq1ajn+jheG8HODvFNdQUFBhB8AANxMUS5Z4YJnAABgKYQfAABgKYQfAABgKYQfAABgKVzwDACoMLKzs3X16lWzy4ALeXp6ysvLy6XbJPwAANye3W7X6dOnlZmZaXYpKAU+Pj6qWrWqy76FTfgBALg1u92uY8eOKSAgQFWrVpWXlxd36K8gDMNQdna20tPTdezYMUlySQAi/AAA3Nrp06cVEBCgu+++m9BTAfn6+iowMFC//vqrTp8+7ZLwwwXPAAC3lZ2drczMTAUHBxN8KjCbzabg4GBlZmYqOzv7trdH+AEAuK28i5tdfUEsyp+8n7ErLmgn/AAA3B5HfSo+V/6MCT8AAMBSCD8AAMBSCD8AAMBS+Ko7AKDC6jV3m9kl6LPBLUq8bmJiogYMGKBvv/1WUVFRLqzKHDt27FBiYqK2b9+uH374QTk5OTIMo8zrIPxYUN6Hwe38gwQA3FpGToYOpx++6fKI4Igyq6U8+Mc//qH58+fr/vvvV2RkpH7++WdT6uC0FwAAcInc3FxlZGTcdPkLL7yg9PR0fffdd+rYsWMZVuaM8AMAgBvLysrSG2+8oQcffFDBwcHy9/dX69attWHDBkcfwzAUERGh7t2751s/IyNDwcHBev755x1tmZmZio+P17333isfHx/VqlVLo0ePzvfsNJvNpqFDh2rRokVq3LixfHx8tGbNmpvWeuedd8rX19cFo749nPYCAMCN2e12zZ8/X71799agQYN04cIFLViwQJ07d9aOHTvUrFkz2Ww29e3bV++++67Onj2rKlWqONb//PPPZbfb1bdvX0nXjt5069ZNW7Zs0eDBg9WwYUPt3btX06dP188//6yVK1c67X/9+vVKTk7W0KFDVbVqVUVERJTh6EuG8AMAgBu74447dPjwYXl7ezvaBg0apAYNGmjWrFlasGCBJKlfv36aMGGCkpOTNWTIEEffpKQkRUREqFWrVpKkTz75ROvWrdOmTZscbZLUpEkTDRkyRF9//bUeeeQRR/tPP/2kvXv3qlGjRqU9VJfhtBcAAG7M09PTEXxyc3N19uxZ5eTkKCoqSrt27XL0q1evnh5++GEtWrTI0Xb27FmtXr1affr0cdxBecmSJWrYsKEaNGig06dPO17t27eXJKfTaZLUpk0btwo+Ekd+AABwewsXLtTUqVN14MABpwd/1q5d26lfv379NHToUB05ckTh4eFasmSJsrOzFRsb6+hz8OBB7d+/X9WqVStwXydPnnR6f+M+3AHhBwAAN5aUlKS4uDjFxMRo1KhRCgsLk6enpyZOnKhDhw459e3Vq5eGDx+uRYsWaezYsUpKSlJUVJTq16/v6JObm6v77rtP06ZNK3B/tWrVcnpfHi5gLi7CDwAAbmzp0qWKjIzU8uXLnR7+GR8fn69vlSpVFB0drUWLFqlPnz7aunWrZsyY4dSnTp062rNnjzp06FBhHxjLNT8AALgxT09PSXK6U/L27du1bVvBd7eOjY3Vvn37NGrUKHl6eqpXr15Oy59++mkdO3ZM8+bNy7fulStXdOnSJRdWbw6O/AAAUM4lJCQUeP+cYcOGqWvXrlq+fLl69Oih6Ohopaamas6cOWrUqJEuXryYb53o6GiFhoZqyZIl6tKli8LCwpyWx8bGOr4RtmHDBrVs2VJXr17VgQMHlJycrJSUlBI/auPIkSP6+OOPJUnfffedJOntt9+WJIWHhztde1SaCD8AgArL7Mf4FPZoi+KYPXt2ge1xcXGKi4tTWlqaPvjgA6WkpKhRo0ZKSkrSkiVLtHHjxnzreHt7q2fPnnr//fcLDBseHh5auXKlpk+fro8++kgrVqyQn5+fIiMjNWzYMNWrV6/E40hNTdXrr7/u1Jb3vk2bNmUWfmyGGU8UK8fsdruCg4OVnp6uoKAgs8spFTzbC0BFkZGRodTUVNWuXVuVK1c2u5x8bhV+zHq21/Dhw7VgwQKlpaXJz8/PlBqK61Y/6+L8/eaaHwAALCQjI0NJSUl68skn3Sb4uBqnvQAAsICTJ09q3bp1Wrp0qc6cOaNhw4aZXZJpCD8AAFjAvn371KdPH4WFhWnmzJlq1qyZ2SWZhvADAIAFtG3bVlzmew3X/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAUE4lJibKZrPpu+++M7uU25abm6vExER169ZNtWrVkr+/v5o0aaK3335bGRkZZVpLubzDc1JSkr766ivt3LlTe/fuVVZWlj788EPFxcUV2N9ut2vcuHFatmyZ0tLSVKNGDT311FOKj49XQEBA2RYPACg/Eruauvs7c67oxFMLTK2hvLh8+bIGDBig5s2ba8iQIQoLC9O2bdsUHx+vf/7zn1q/fr1sNluZ1FIuw89rr72mI0eOqGrVqqpRo4aOHDly076XLl1SmzZttHv3bnXq1Em9e/fW999/rylTpmjTpk3avHmzKleuXIbVAwBgTbm5ucrKyirw7663t7e2bt2qRx55xNE2aNAgRUREOALQo48+WiZ1lsvTXvPnz9fhw4d16tQpDRkypNC+7777rnbv3q0//elPSklJ0aRJk5SSkqI//elP+vbbbzV9+vQyqhoAgLKXlZWlN954Qw8++KCCg4Pl7++v1q1ba8OGDY4+hmEoIiJC3bt3z7d+RkaGgoOD9fzzzzvaMjMzFR8fr3vvvVc+Pj6qVauWRo8erczMTKd1bTabhg4dqkWLFqlx48by8fHRmjVrCqzT29vbKfjk6dGjhyRp//79JRp/SZTL8PPoo48qPDz8lv0Mw9D8+fMVEBCg119/3WnZ66+/roCAAM2fP7+0ygQAwHR2u13z589X27ZtNXnyZI0bN06nTp1S586dtXv3bknXQkrfvn21evVqnT171mn9zz//XHa7XX379pV07ehNt27dNGXKFD3++OOaNWuWYmJiNH36dPXs2TPf/tevX6/hw4erZ8+eeu+99xQREVGs+tPS0iRJVatWLf7gS6hcnvYqqoMHD+r48ePq3Lmz/P39nZb5+/urZcuWSklJ0dGjR1WrVi2TqgQAoPTccccdOnz4sLy9vR1tgwYNUoMGDTRr1iwtWHDtmqN+/fppwoQJSk5OdjqrkpSUpIiICLVq1UqS9Mknn2jdunXatGmTo02SmjRpoiFDhujrr792OoLz008/ae/evWrUqFGJ6n/33XcVFBSkLl26lGj9kiiXR36K6uDBg5KkunXrFrg8rz2vX0EyMzNlt9udXgAAuAtPT09H8MnNzdXZs2eVk5OjqKgo7dq1y9GvXr16evjhh7Vo0SJH29mzZ7V69Wr16dPHcbHxkiVL1LBhQzVo0ECnT592vNq3by9JTqfTJKlNmzYlDj7vvPOO1q1bp0mTJikkJKRE2ygJtw4/6enpkqTg4OAClwcFBTn1K8jEiRMVHBzseHGECADgbhYuXKj7779flStXVmhoqKpVq6Yvvvgi39+/fv36aevWrY4vEi1ZskTZ2dmKjY119Dl48KD+9a9/qVq1ak6vevXqSZJOnjzptM3atWuXqObFixfrtdde07PPPqsXXnihRNsoKbc+7eUKY8aM0YgRIxzv7XY7AQgA4DaSkpIUFxenmJgYjRo1SmFhYfL09NTEiRN16NAhp769evXS8OHDtWjRIo0dO1ZJSUmKiopS/fr1HX1yc3N13333adq0aQXu78a/kb6+vsWu+csvv1S/fv0UHR2tOXPmFHv92+XW4SfviM/NjuzkncK62ZEhSfLx8ZGPj4/riwMAoAwsXbpUkZGRWr58udN9cuLj4/P1rVKliqKjo7Vo0SL16dNHW7du1YwZM5z61KlTR3v27FGHDh1K5b4727dvV48ePRQVFaXk5GRVqlT2UcStT3vd6pqeW10TBACAu/P09JR07RvQebZv365t27YV2D82Nlb79u3TqFGj5OnpqV69ejktf/rpp3Xs2DHNmzcv37pXrlzRpUuXSlzr/v37FR0drYiICK1atapER41cwa2P/NStW1c1a9bU1q1bdenSJadvfF26dElbt25V7dq1OY0FAHBrCQkJBd4/Z9iwYeratauWL1+uHj16KDo6WqmpqZozZ44aNWqkixcv5lsnOjpaoaGhWrJkibp06aKwsDCn5bGxsY5vhG3YsEEtW7bU1atXdeDAASUnJyslJUVRUVHFHsOFCxfUuXNnnTt3TqNGjdIXX3zhtLxOnTpq0aJFsbdbEm4dfmw2m5577jm9+eabeuuttzRp0iTHsrfeeksXL17U2LFjTawQAGCquFWm7v5E+mGXbGf27NkFtsfFxSkuLk5paWn64IMPlJKSokaNGikpKUlLlizRxo0b863j7e2tnj176v3333e60DmPh4eHVq5cqenTp+ujjz7SihUr5Ofnp8jISA0bNsxx4XNxnTlzRkePHpUkvfrqq/mW9+/fv8zCj824/jhZOTF//nxt2bJFkrR3717t2rVLLVu21L333itJatWqlZ577jlJ147wtGzZUnv27FGnTp30wAMPaNeuXVq7dq1++9vfatOmTcU6rGa32xUcHKz09HTHt8Uqml5zrx0K/Wxw2fySAUBpycjIUGpqqmrXrl0uH2V0+BbhJyI4okzquNHw4cO1YMECpaWlyc/Pz5QaiutWP+vi/P0ul0d+tmzZooULFzq1bd26VVu3bnW8zws//v7+2rRpk+PBphs2bFCNGjU0cuRIxcfHm3Y+EQCA8igjI0NJSUl68skn3Sb4uFq5DD+JiYlKTEwscv/g4GBNnz6d53gBAHATJ0+e1Lp167R06VKdOXNGw4YNM7sk05TL8AMAAFxr37596tOnj8LCwjRz5kw1a9bM7JJMQ/gBAMAC2rZtq3J4ma8p3Po+PwAAAMVF+AEAAJZC+AEAAJZC+AEAAJZC+AEAAJZC+AEAAJZC+AEAAJZC+AEAAJZC+AEAAJbCHZ4BABXWwJSBpu4/IydD77R6p8TrJyYmasCAAfr2228VFRXlwsrMMW/ePCUlJenAgQM6f/68atasqbZt2yo+Pl4RERFlVgfhBwAAlInvv/9etWvXVrdu3XTHHXcoNTVV8+bN06pVq7Rnzx7VrFmzTOog/AAAAJfIzc1VVlaWKleuXODy999/P19bTEyMoqKi9NFHH+nVV18t7RIlcc0PAABuLSsrS2+88YYefPBBBQcHy9/fX61bt9aGDRscfQzDUEREhLp3755v/YyMDAUHB+v55593tGVmZio+Pl733nuvfHx8VKtWLY0ePVqZmZlO69psNg0dOlSLFi1S48aN5ePjozVr1hSr/rzTXefPny/WereDIz8AALgxu92u+fPnq3fv3ho0aJAuXLigBQsWqHPnztqxY4eaNWsmm82mvn376t1339XZs2dVpUoVx/qff/657Ha7+vbtK+na0Ztu3bppy5YtGjx4sBo2bKi9e/dq+vTp+vnnn7Vy5Uqn/a9fv17JyckaOnSoqlatWqRrd86cOaOrV6/qP//5j958801JUocOHVw2J7dC+AEAwI3dcccdOnz4sLy9vR1tgwYNUoMGDTRr1iwtWLBAktSvXz9NmDBBycnJGjJkiKNvUlKSIiIi1KpVK0nSJ598onXr1mnTpk2ONklq0qSJhgwZoq+//lqPPPKIo/2nn37S3r171ahRoyLXfNdddzmOIoWGhmrmzJnq2LFjySagBDjtBQCAG/P09HQEn9zcXJ09e1Y5OTmKiorSrl27HP3q1aunhx9+WIsWLXK0nT17VqtXr1afPn1ks9kkSUuWLFHDhg3VoEEDnT592vFq3769JDmdTpOkNm3aFCv4SNLq1av1j3/8Q1OnTtU999yjS5culWjsJcWRHwAA3NzChQs1depUHThwQNnZ2Y722rVrO/Xr16+fhg4dqiNHjig8PFxLlixRdna2YmNjHX0OHjyo/fv3q1q1agXu6+TJk07vb9xHUbRr106S1KVLF3Xv3l1NmjRRQECAhg4dWuxtlQThBwAAN5aUlKS4uDjFxMRo1KhRCgsLk6enpyZOnKhDhw459e3Vq5eGDx+uRYsWaezYsUpKSlJUVJTq16/v6JObm6v77rtP06ZNK3B/tWrVcnrv6+t7W/XXqVNHv/nNb7Ro0SLCDwAAuLWlS5cqMjJSy5cvd5y6kqT4+Ph8fatUqaLo6GgtWrRIffr00datWzVjxgynPnXq1NGePXvUoUMHp+2VpitXruT7Jllp4pofAADcmKenp6RrX2fPs337dm3btq3A/rGxsdq3b59GjRolT09P9erVy2n5008/rWPHjmnevHn51r1y5UqJr8/JycnRuXPn8rXv2LFDe/fuLdM7WHPkBwCAci4hIaHA++cMGzZMXbt21fLly9WjRw9FR0crNTVVc+bMUaNGjXTx4sV860RHRys0NFRLlixRly5dFBYW5rQ8NjbW8Y2wDRs2qGXLlrp69aoOHDig5ORkpaSklCioXLx4UbVq1VLPnj3VuHFj+fv7a+/evfrwww8VHBys119/vdjbLCnCD2AliV2L1i9uVenWAZSRhM4Jpu7/cPphl2xn9uzZBbbHxcUpLi5OaWlp+uCDD5SSkqJGjRopKSlJS5Ys0caNG/Ot4+3trZ49e+r99993utA5j4eHh1auXKnp06fro48+0ooVK+Tn56fIyEgNGzZM9erVK9EY/Pz89Nxzz2nDhg1aunSprly5opo1a6p379567bXXyvTZXjbj+uNkkN1uV3BwsNLT0xUUFGR2OaWi19xrh0I/G9zC5EpQ5gg/qGAyMjKUmpqq2rVr3/SRCma6VfiJCI4okzpuNHz4cC1YsEBpaWny8/MzpYbiutXPujh/v7nmBwAAC8nIyFBSUpKefPJJtwk+rsZpLwAALODkyZNat26dli5dqjNnzmjYsGFml2Qawg8AABawb98+9enTR2FhYZo5c6aaNWtmdkmmIfwAAGABbdu2FZf5XsM1PwAAwFIIPwAAt8cRjYrPlT9jwg8AwG15eXnJZrOV+VPBUfYuXbokm80mLy+v294W1/wAANyWp6engoODderUKWVmZiooKEiVKlUqs2dS3crVrKuFLs/IyCijStyTYRjKycmR3W6X3W5XSEiI43Eet4PwAwBwa9WrV5evr69Onjwpu91udjlOzlw5U+jyLN+sMqrEvXl6eqpGjRoKDg52yfYIPwAAt2az2RQSEqLg4GBdvXpVOTk5ZpfkMG9L/oeDXu+dVu+UUSXuq1KlSvL09HTp0TzCDwCgQrDZbKpUqZIqVSo/f9rOXz1f6PLy+EgOK+CCZwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCkVIvwYhqHly5erXbt2qlGjhvz8/FS/fn09//zz+ve//212eQAAoBypEOHnlVde0ZNPPqmffvpJMTEx+uMf/6jatWtr3rx5atasmX788UezSwQAAOVEJbMLuF1paWmaMWOGwsPDtWfPHgUHBzuWTZ8+XSNGjNC0adOUkJBgYpUAAKC8cPsjP4cPH1Zubq5atmzpFHwkqWvXrpKkU6dOmVEaAAAoh9w+/NStW1fe3t7aunWr7Ha707JVq1ZJkjp06GBGaQAAoBxy+9NeoaGhmjRpkkaOHKkGDRqoe/fuCgoK0p49e7R+/Xq9+OKLGjp06E3Xz8zMVGZmpuP9jQEKAABULG4ffiRp+PDhuuuuu/Tcc89pzpw5jvZWrVrpmWeeUaVKNx/mxIkTNX78+LIo00mvudsc//3Z4BZlvn+UQ4ld87fFrSr7OlDqBqYMLHR5QueKeY1iYeOuqGNG+eT2p70k6c0331Tfvn01duxYHT16VBcuXNBXX32ljIwMtW3bVn//+99vuu6YMWOUnp7ueB09erQMKwcAAGXN7cPPunXrFB8fr6FDh+rVV1/V3XffrYCAALVq1Uqff/65vLy8NHLkyJuu7+Pjo6CgIKcXAACouNw+/KxevVqS1K5du3zLqlevrgYNGuiXX37RxYsXy7o0AABQDrl9+MnKypJ086+znzp1Sh4eHvLy8irLsgAAQDnl9uGnZcuWkqRp06YpPT3dadmcOXP066+/qkWLFvLx8TGjPAAAUM64/be9nnrqKc2ePVubN29WvXr11K1bN4WEhGjXrl1av369fH19NW3aNLPLBAAA5YTbhx9PT0+tXbtW06dPV3Jysj755BNlZWXpzjvvdHwDrGHDhmaXCQAAygm3Dz/StW9svfrqq3r11VfNLgUAAJRzbn/NDwAAQHEQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKUQfgAAgKVUMrsASL3mbpMkfTa4RbH637hOYdu5fh1UQIldza7AWUH1xK0q/XXLGxPGMjBl4G2tn9A5wUWVAOUXR34AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClEH4AAIClFDv8jBgxQmvXri2NWgAAAEpdscPPjBkz9M033zi1TZ48WaGhoS4rqqRWrFihjh07KjQ0VJUrV1bt2rXVu3dvHT161OzSAABAOVHJFRvJyMjQ+fPnXbGpEjEMQ0OGDNHcuXNVp04d9erVS4GBgTp+/Lg2bdqkI0eOqFatWqbVBwAAyg+XhB+zzZw5U3PnztWLL76omTNnytPT02l5Tk6OSZUBAIDyxu0veL5y5YrGjx+vyMhIvffee/mCjyRVqlQhMh4AAHABt08Fa9eu1blz5zRgwABdvXpVf//73/Xzzz8rJCREjz76qO69916zSwQAAOVIicLPr7/+qh07dji9l6Rvv/1WhmEUuM5DDz1Ukl3d0s6dOyVJnp6euv/++/Xzzz87lnl4eGj48OGaMmXKTdfPzMxUZmam473dbi+VOgEAQPlQovCzYMECLViwwKnNMAw1b978putcvXq1JLu6pZMnT0qSpk2bpgceeEA7duxQw4YN9f3332vw4MGaOnWq6tSpoxdeeKHA9SdOnKjx48eXSm036jV3W7H7fja4hcu2WdTtFLTPwuq5VQ23GgNwS4ld87fFrSq79Uu6j1IwMGVgmezHSm41pwmdE8qokuIpz3UXVlt5mM9ih5/+/fuXRh0llpubK0ny9vbWypUrVbNmTUlS69attWTJEjVt2lRTp069afgZM2aMRowY4Xhvt9v5ZhgAABVYscPPhx9+WBp1lFhwcLAkKSoqyhF88jRp0kSRkZH65ZdfdP78eYWEhORb38fHRz4+PmVRKgAAKAfc/tte9evXl6QCg8317VeuXCmjigAAQHl229/2unDhgnbu3KnTp09LkqpVq6YHHnhAgYGBt11cUbRr106StH///nzLsrOz9csvv8jf31/VqlUrk3oAAED5VuIjPz/++KO6du2qKlWqqEOHDurZs6d69uyp9u3bKzQ0VDExMdq3b58ray1QnTp11KlTJ/3yyy+aP3++07JJkybp/Pnz6tGjB/f6AQAAkkp45GfTpk16/PHHdfHiRfn5+enBBx90XG9z/Phx7dy5U3//+9+1ceNGffHFF2rZsqVLi77R+++/r0ceeUSDBg3SypUr1aBBA33//fdav369wsPD9ec//7lU9w8AANxHscPP5cuXFRsbq8uXL2vcuHEaOXKk/P39nfpcunRJU6ZM0VtvvaW+fftq//79qly5ssuKvlGdOnX03Xff6Y033tCaNWu0du1aVa9eXX/4wx/0xhtvKCwsrNT2DQAA3Euxw09ycrJ+/fVXTZ48WaNGjSqwj7+/v+Lj4+Xr66sxY8ZoyZIlio2Nve1iC1OrVq1y9000AABQ/hT7mp9//OMfqlatml5++eVb9n355ZcVGhqqVatcfDMxAACAEip2+NmzZ49at24tLy+vW/b19vbW//zP/2j37t0lqQ0AAMDlih1+Tp48qYiIiCL3r127tuMRFAAAAGYrdvi5cOGCgoKCitw/ICBAFy9eLO5uAAAASkWxw0/es7RKex0AAIDSUKL7/Pz4449KTk4ucl8AAIDyokThZ9myZVq2bFmR+hqGIZvNVpLdAAAAuFyxw098fHxp1AEAAFAmCD8AAMBSSvRg023btql9+/YKDAxUUFCQOnbsqB07dri6NgAAAJcr9pGfvXv3qn379srMzHS0/fOf/9TXX3+tHTt2qHHjxi4tEAAAwJWKfeRn0qRJyszM1P/+7/8qLS1NaWlpev3113XlyhVNnjy5NGoEAABwmWIf+fnqq6/UqlUrvfXWW4628ePHa+PGjdq0aZNLiwMAAHC1Yh/5OXHihJo3b56v/eGHH9aJEydcUhQAAEBpKXb4yc7OVkBAQL52f39/ZWdnu6QoAACA0lKib3sBAAC4qxLd4TkpKUnffPONU9svv/wiSXrsscfy9bfZbPriiy9KsisAAACXKlH4+eWXXxxh50Zr1qzJ18bjLQAAQHlR7PCTmppaGnUAAACUiWKHn/Dw8NKoAwAAoExwwTMAALAUwg8AALAUwg8AALCUEn3bC8BtSOxq7vq3s4+4VUXvezv7sbiBKQPL5b4TOieUYSXF465130pp/i5U1DkrCo78AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAAS6mw4Wfy5Mmy2Wyy2Wz65ptvzC4HAACUExUy/Pz444+Kj4+Xv7+/2aUAAIBypsKFn+zsbPXv31/NmjVTjx49zC4HAACUMxUu/EyYMEH/+te/lJCQIE9PT7PLAQAA5UwlswtwpV27dmnChAl688031ahRI7PLAQAA5VCFCT+ZmZnq16+fmjVrptGjRxdrvczMTMd7u91eGuUBAIByosKEnzfeeEMHDx7Uzp07i3W6a+LEiRo/fnwpVlZ0veZuKxf7y2v/bHCLIq+DUpLY1ewKnN1OPa4ey822F7fKtftBuTAwZWCF3Le7btvdVYhrfrZt26YpU6botddeU5MmTYq17pgxY5Senu54HT16tJSqBAAA5YHbH/nJyclR//79df/99+vVV18t9vo+Pj7y8fEphcoAAEB55Pbh5+LFizp48KAkydvbu8A+LVpcO32zYsUKxcTElFVpAACgHHL78OPj46Nnn322wGWbN2/WwYMH1a1bN1WrVk0RERFlWxwAACh33D78+Pr6av78+QUui4uL08GDBzVmzBg1b968jCsDAADlUYW44BkAAKCoCD8AAMBSKnT4SUxMlGEYnPICAAAOFTr8AAAA3IjwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALKWS2QWgcL3mbnP892eDW9zW+mW5LlChJXY1uwJTDEwZyLYtoqLPGUd+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApbh9+Dl27JhmzJihTp066Z577pG3t7eqV6+uJ598Utu3bze7PAAAUM64ffiZNWuWhg8frn//+9/q1KmTRo4cqVatWulvf/ubHnnkES1evNjsEgEAQDlSyewCbtdDDz2kjRs3qk2bNk7tX331lTp06KAXXnhBMTEx8vHxMalCAABQnrj9kZ8nnngiX/CRpNatW6tdu3Y6d+6c9u7da0JlAACgPHL78FMYLy8vSVKlSm5/gAsAALhIhU0F//nPf7Ru3TrVqFFD99133037ZWZmKjMz0/HebreXRXkAAMAkFTL8ZGdnKzY2VpmZmZo8ebI8PT1v2nfixIkaP358GVZXcr3mbjO7BKDiSOyavy1uVdH6AXBrFe60V25uruLi4rR582YNGjRIsbGxhfYfM2aM0tPTHa+jR4+WUaUAAMAMFerIT25urgYOHKhPPvlEffv21Zw5c265jo+PD98EAwDAQipM+MnNzdWAAQP00UcfqXfv3kpMTJSHR4U7sAUAAG5ThUgH1wefnj176uOPPy70Oh8AAGBdbh9+8k51ffTRR3rqqaeUlJRE8AEAADfl9qe93nzzTS1cuFABAQGqV6+e3n777Xx9YmJi1KxZs7IvDgAAlDtuH34OHz4sSbp48aImTJhQYJ+IiAjCDwAAkFQBwk9iYqISExPNLgMAALgJt7/mBwAAoDgIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIIPwAAwFIqmV0AXK/X3G1ml+Dk+no+G9zCxEpgCYldza4AQDnHkR8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGApFSb8fPvtt3rssccUEhIif39/NW/eXMnJyWaXBQAAyplKZhfgChs2bFDnzp1VuXJl9erVS4GBgVq2bJl69uypo0ePauTIkWaXCAAAygm3P/KTk5OjQYMGycPDQ5s3b9bcuXM1depU7dmzR/Xq1dPYsWN15MgRs8sEAADlhNuHn/Xr1+vQoUN65pln1KxZM0d7cHCwxo4dq6ysLC1cuNC8AgEAQLni9uFn48aNkqROnTrlW9a5c2dJ0qZNm8qyJAAAUI65/TU/Bw8elCTVrVs337Lq1asrICDA0acgmZmZyszMdLxPT0+XJNntdhdXKmVfueTybbqb0phXt3Ml2+wKcDMF/X66+udltyvrUpZrtwm4kdL6O5C3XcMwbt3ZcHMdO3Y0JBkHDx4scHnNmjWNoKCgm64fHx9vSOLFixcvXrx4VYDX0aNHb5kd3P7Iz+0aM2aMRowY4Xifm5urs2fPKjQ0VDabzWX7sdvtqlWrlo4ePaqgoCCXbdedMAfMgdXHLzEHEnNg9fFLpTMHhmHowoULqlmz5i37un34CQ4OlvT/T1fdyG6364477rjp+j4+PvLx8XFqCwkJcVl9NwoKCrLsL3se5oA5sPr4JeZAYg6sPn7J9XOQlwluxe0veM671qeg63rS0tJ08eLFAq8HAgAA1uT24adNmzaSpLVr1+ZblpKS4tQHAADA7cNPhw4dFBkZqU8++US7d+92tKenp+udd96Rt7e3+vXrZ16B/8fHx0fx8fH5TrFZCXPAHFh9/BJzIDEHVh+/ZP4c2AyjKN8JK99u9niLI0eOaMqUKTzeAgAAOFSI8CNJO3bsUHx8vL7++mtlZ2frvvvu04gRI9SzZ0+zSwMAAOVIhQk/AAAAReH21/wAAAAUB+EHAABYCuGnCL799ls99thjCgkJkb+/v5o3b67k5ORibSMzM1Nvvvmm6tatq8qVK6tmzZoaPHiwTp48WaT1H3vsMdlsNlWuXLkkQ7htZs1BVlaWpk2bpqioKAUGBiowMFBNmjTRH/7wh9sdUrGYMf4rV65o2rRpeuCBB3THHXcoJCRETZs21YQJE256U8/SdLtzcOjQIY0bN07dunXTXXfdJZvNpoiIiFuul5KSojZt2igwMFBBQUFq166d/vnPf97GSEqurOfg4MGDeuedd/Q///M/qlmzpry9vVWrVi3169dPBw4ccMGIises34HrvfDCC7LZbLLZbEpLSyvmCG6fWXOQm5urhIQEtWrVSiEhIfLz81O9evU0YMAAXbhw4TZGVHxmzEFOTo4SEhLUokULVatWTYGBgWrUqJFGjx5dst+D4j9Ny1rWr19veHl5GYGBgcagQYOMESNGGOHh4YYkY8qUKUXaxtWrV43OnTsbkozmzZsbf/rTn4wnnnjCsNlsRmRkpHHy5MlC1587d67h4eFhVK5c2fDx8XHFsIrFrDk4e/as8dBDDxmSjEceecQYOXKkMXLkSOOJJ54wQkNDXT3MmzJj/FlZWcbDDz9sSDKaNWtmvPzyy8bLL79sNG3a1JBkNG7c2Lh06VJpDLdArpiDDz/80JBkeHp6Gk2aNDE8PDyM8PDwQtf5+OOPDUlGtWrVjKFDhxpDhw41qlWrZthsNmPJkiUuGFnRmTEHPXv2NCQZTZo0MYYMGWKMHj3a6NKliyHJ8PX1NTZt2uSi0d2aWb8D11u7dq0hyfD39zckGf/9739LOJqSMWsOMjIyjK5duxqSjPvvv98YNmyYMXr0aKNXr15GWFhYkZ5l5SpmzcETTzxhSDLuvfdeY+jQocbIkSONli1bGpKMGjVqFPt3gfBTiOzsbKNOnTqGj4+P8f333zvaz58/b9SrV8/w9vY2Dh8+fMvtJCQkGJKM3r17G7m5uY722bNnG5KMwYMH33Td1NRUIzAw0HjllVeM8PDwMg8/Zs5BTEyMYbPZjEWLFhVYV1kwa/yLFy82JBk9evTIt63u3bsbkoyFCxeWfGDF4Ko5OHTokLFt2zbj8uXLhmEYho+PT6EfeGfPnjVCQkKMqlWrOn24Hz161KhatapRtWpVw263l3hcxWHWHHz44YfGrl278rV/+umnhiSjUaNGxR5LSZg1/uudP3/euPvuu43f//73Rps2bco8/Jg5By+//LIhyZg0aVK+ZVevXjWuXr1arLGUlFlzsH37dkOS8dBDDxlZWVlOy1566SVDkjF+/PhijYXwU4iUlBRDkjFgwIB8yxITE4s84S1atDAk5fulyM3NNSIjIw1/f3/HL8GNy9u1a2fUq1fPuHz5sinhx6w52LZtmyHJiI2Nvf1B3Aazxj9x4kRDkjF37tx825o7d26x/i/rdrlqDm50qw+8Dz744KbbHjduXJkGQLPmoDD16tUzJBmnTp0q0frFUR7G379/fyM0NNQ4ceKEKeHHrDn49ddfjUqVKhmtW7cu9rZdzaw5yAv7Y8eOzbcs72jg0KFDi7VPrvkpxMaNGyVJnTp1yresc+fOkqRNmzYVuo2MjAxt375d9evXV3h4uNMym82mjh076tKlS/ruu+/yrTtr1ixt2rRJCQkJ8vX1LeEobo9Zc7B48WJJ0lNPPaXTp08rISFBEydOVFJSks6cOXM7QyoWs8bfpEkTSdLq1avzbe+LL76QzWZTu3btijWWknLFHLjTfst7LXm8vLwkSZUqlf7zqc0e/+eff66FCxdq1qxZCgsLK7X9FMasOVi6dKlycnL01FNP6cKFC1q0aJEmTpyohIQEHTt2zOX7K4xZc9C4cWNJ0rp165Sdne20bNWqVZKuPe2hONz+qe6lKe9hqQU9GLV69eoKCAgo8IGq1zt06JByc3Nv+nDV6x/M2rp1a6d9jxkzRi+99JJatmxZ0iHcNrPmYOfOnY62vn37ym63O/oHBARo/vz5ZXIDS7PGHx0drZiYGK1YsUK/+c1v1LZtW0nX7maempqquXPn6oEHHijpsIrFFXPg6v0W9kDj0mDWHNzMjh079K9//Uu//e1vFRISUur7M3P8Z86c0aBBgxQTE6PevXuXyj6Kwqw5yPssPH/+vOrXr6///ve/jmXe3t6aNGmShg8f7vL9FsSsObjvvvs0bNgwvffee2rUqJG6dOkiHx8fbdu2TTt37tT48eMVExNTrG1y5KcQed+oCQ4OLnB5UFDQLb91U5RtXN9PunZVf//+/VWjRg1NmDCh2HW7kllzkPcNqNGjRysmJkaHDh3SuXPnlJSUJA8PD8XGxuqHH34o3mBKwKzx22w2LVu2TH/605+0Z88ezZgxQzNmzNCePXvUo0cPdezYsdhjKSlXzIGr91vQnJUms+bgZrX0799fHh4eevfdd8tsn5I543/xxReVlZWl2bNnl8r2i8qsOcj7LBw/fryaNm2qf/3rX7Lb7Vq1apWqVq2qESNGFHiEuDSY+XuQ9xl45MgRzZo1S1OmTNHWrVvVsWNHPfHEE8XeHuGnHPrzn/+sb775RgsWLJCfn5/Z5ZgiNzdX0rXEn5iYqMjISIWEhKhPnz6aNGmSsrOzNXPmTJOrLD2XL19Wjx49lJiYqE8//VSnT5/W6dOn9dlnn2nNmjV66KGHdPjwYbPLRBm7cuWKevTooQMHDuitt95yHBGsqBYvXqzk5GS99957ql69utnlmCLvszAsLEzLli1To0aNFBgYqOjoaM2fP1+SNHXqVDNLLHW5ubkaPHiwXnvtNc2aNUv//e9/lZ6ern/84x/av3+/mjdvrm+//bZY2yT8FCIv3d4sydrt9psm4OJs4/p+P//8s+Lj4/Xiiy+qTZs2JarblcyYg+v/+/HHH5fNZnPq361bN0kq8DopVzNr/O+8847+/ve/a+7cuerZs6dCQ0MVGhqqnj176oMPPtDJkyfL7KigK+bA1fstaM5Kk1lzcL2MjAx1795dGzZs0JgxYzR27NhS3d/1zBj/2bNn9Yc//EHR0dGKjY116bZLwux/B48++mi+/xnu3LmzfHx8yuSz8PpaynoOEhISNG/ePE2YMEHPP/+8qlevrqCgIHXp0kVLly7VpUuXiv3vgfBTiMKuK0hLS9PFixdveh1HnsjISHl4eNz0POiN51D37dunzMxM/fWvf3XcyCvvdeTIEWVmZjrenz9//jZGVzRmzIEk1a9fX5IKvJ4hr+3KlSu3rP92mTX+vMPYBV3UnNf2/fffF2EEt88Vc+Dq/RZ27UFpMGsO8ly5ckXdunXTl19+qdGjR+udd94ptX0VxIzx/+c//9GZM2ccF/hf/8q7qLZGjRqy2WzavXu3S/ddELN+Bwr7LPTw8FBgYGCZfBZK5s1BYZ+HTZs21R133FHsz0PCTyHyjrysXbs237KUlBSnPjfj6+urhx56SD/99JOOHDnitMwwDH355Zfy9/dXVFSUJCkiIkLPPvtsga+AgAB5eno63vv4+LhimIUyYw4kqX379pKuhcEb5bUV986wJWHW+LOysiRJp06dyre9vLay+PlLrpkDd9pveavlypUr6t69u7788ku98sormjx5cqnspzBmjD80NPSmn4V5p8CeeeYZPfvsswoNDXXpvgti1u9AYZ+Fp06d0unTp8vks1Aybw4K+zzMzMzUhQsXiv95WKwvxltMdna2ERkZWegNnVJTUx3tx48fN/bv32+cP3/eaTu3c5PD65l1k0Mz5iA9Pd2oWrWqUblyZeOHH35wtGdmZjrucDt//nzXDrYAZo3/+eefNyQZ/fr1c7qBWU5OjtGnTx9DkvG///u/rh3sTbhqDm5UlJscBgcHl5ubHJoxB1euXDE6duxoSDJGjBhxm6MoObPGfzNm3eTQjDnIyckxGjZsaEgy1q5d62jPzc01nnvuOUOS8dprr5V0WMVi1hzk3fesQ4cORkZGhtOyV1991ZBk9OnTp1hjIfzcQnFu5d2/f39DkvHhhx86tRf0aIMnn3zSsNlsRu3atW/5eIs8ZoQfwzBvDlasWGF4enoafn5+Rr9+/Yxhw4YZjRs3NiQZjz32mJGTk1Oaw3YwY/xHjhwxqlevbuj/HmXxxz/+0fjjH/9oNGrUyJBk1K1b1zh79mxpD93BFXNw6tQpo3///o6Xh4eH4e/v79R24w37Cnu8RXJycmkP24kZc5C3nerVqxvx8fEFvq7/Y1OazPodKIgZ4ccwzJuDb775xvDz8zMqVapkPP3008aIESMcj/554IEHjIsXL5b20B3MmIP09HSjQYMGhiQjIiLCGDJkiDF8+HDHHFSrVs04dOhQscZB+CmC7du3G7/73e+MoKAgw9fX13jooYeMzz77LF+/m/2gDePas1nGjRtn1KlTx/D29jaqV69uPPfcc0ZaWlqR6zAr/BiGeXOwZcsW43e/+50REhJieHt7G40bNzYmT55cZo+3yGPG+I8dO2YMHTrUuPfeew1vb2/Dx8fHqF+/vjFq1KgyDT55bncOUlNTDUmFvgr6Q7569WqjdevWhr+/vxEQEGC0adPG+PLLL0tplIUr6znI+yNf2GvDhg2lO+jrmPU7cCOzwo9hmDcHP/74o/Hkk08aoaGhhpeXl1GnTh1jzJgxxoULF0pppDdnxhycP3/eGDNmjNGoUSOjcuXKhpeXl1G7dm1jyJAhJXq2mc0wDKPwE2MAAAAVBxc8AwAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AAAASyH8AG6kbdu2stlsZpeBciQuLk42m83xmjNnjtklqXr16k41HT582OySACeEH8Ak1/9xKMoLpevw4cOy2WyKi4szZf+JiYmy2WxKTEws0frDhg1TfHy8oqKiXFtYCbzyyiuKj49X06ZNzS4FKFAlswsArCo+Pj5f24wZM5Senl7gMkn66KOPdPny5dIuDW7o5ZdfVkREhNllSLoWfqRrgXLPnj0mVwPkR/gBTDJu3Lh8bYmJiUpPTy9wmSTdc889pVsUAFgAp70AN1LQNT/Xny75/PPP9fDDD8vPz0933XWXXn/9deXm5kqSFi5cqKZNm8rX11f33HOP/vznPxe4D8MwlJCQoJYtWyooKEh+fn6KiopSQkJCsevdvHmzYmJidOedd8rHx0e1atXSE088oS1btjj1u3TpkuLj49WgQQNVrlxZVapUUXR0tLZu3Zpvm+PGjZPNZtPGjRv1ySefqFmzZvL19VWNGjU0bNgwXblyJd86y5YtU5s2bRQWFqbKlSurZs2aevTRR7Vs2TLHHNauXdsxT9efbty4caMk6fjx44qPj1fz5s0VFhYmHx8fRURE6MUXX9TJkyfz7TPvWpzU1FTNnDlTDRo0kI+Pj8LDwzV+/HjHzyWv74ABAyRJAwYMcOnpTpvNprZt2+rYsWN65plnVLVqVQUGBio6Olr//ve/JUn79+9XTEyMqlSposDAQP3+97/XiRMn8m1rw4YN6tKli2rWrCkfHx/deeedat26tebOnXvbdQJliSM/QAWxYsUKrV27VjExMWrZsqW++OILvf322zIMQ8HBwXr77bfVvXt3tW3bVsuWLdPo0aN15513ql+/fo5tGIahPn366NNPP1XdunX1zDPPyNvbW19++aWeffZZ7du3T1OmTClSPe+9956GDx8uX19f9ejRQ/fcc4+OHTumLVu2aOnSpWrVqpUkKSMjQ+3bt9eOHTv0wAMP6OWXX9aJEye0ePFipaSk6NNPP9VTTz2Vb/t/+ctftGbNGnXv3l3t27fXmjVrNHPmTJ0+fVqLFi1y9Js9e7ZefPFF1ahRQz169FBoaKjS0tK0Y8cOrVixQk8++aSaNWumYcOG6b333lPTpk0VExPjWD/vVNLmzZs1depUdejQQQ8//LC8vLz0/fffa/bs2UpJSdGuXbsUHBycr85Ro0Zp06ZN6tq1qzp37qyVK1dq3LhxysrK0oQJEyRJMTExOn/+vP72t7+pe/fuatasWZHmuKjOnTunVq1aqXr16urfv79+/vlnrVq1SgcOHNDf/vY3tW7dWg8++KAGDhyonTt3atmyZTp79qzWr1/v2MYXX3yhxx9/XCEhIerevbtq1KihU6dOac+ePfr44481ePBgl9YMlCoDQLkRHh5uFPbPsk2bNvmWf/jhh4Ykw8vLy9ixY4ej3W63G2FhYYafn59RvXp149ChQ45l//nPfwxvb2/jvvvuc9rW3LlzDUnGgAEDjKysLEd7Zmam8fjjjxuSjO++++6W49i9e7fh4eFh1KxZ00hNTXValpubaxw7dszxfvz48YYko0+fPkZubq6jfdeuXYa3t7cREhJi2O12R3t8fLwhyQgODjYOHDjgaL98+bJRr149w8PDw2n7DzzwgOHt7W2cOHEiX52nT592/Hdqaqohyejfv3+BYzpx4oRx4cKFfO0LFy40JBlvv/22U3v//v0NSUbt2rWN48ePO9pPnTplhISEGIGBgUZmZqajPe/n+OGHHxa4/5vJ28+N85xHkiHJGD58uFP7Cy+8YEgyQkJCjBkzZjjac3Nzjccee8yQZOzcudPR/sQTTxiSjN27d+fbx/XzWJzaALNw2guoIPr27avf/va3jveBgYHq2rWrLl++rBdeeEGRkZGOZbVq1VKrVq20b98+5eTkONr/8pe/yN/fX3/961/l5eXlaPf29nYcpfj0009vWcsHH3yg3Nxcvf322/kuwrXZbKpZs6bj/cKFC+Xl5aVJkyY5neb5zW9+o/79++v8+fNauXJlvn0MGzZM9evXd7z39fVV7969lZubq507dzr19fLychpPntDQ0FuOJU9YWJgCAgLytcfGxiooKEjr1q0rcL3XX39dNWrUcLyvWrWqunfvrgsXLuinn34q8v5vR0BAgN5++22ntt69e0u6NgcvvfSSo91ms6lXr16SVODFyr6+vvnaijOPQHnAaS+ggijoVEneH92bLbt69apOnDihu+66S5cvX9bevXtVs2ZNTZ48OV//7OxsSdKBAwduWcuOHTskSZ06dSq0n91u17///W81bNhQd999d77l7dq107x587R7927FxsY6LXvwwQfz9c/bxvnz5x1tvXr10ujRo9WkSRM988wzateunVq1aqWgoKBbjuNGy5cv1wcffKBdu3bp3Llzunr1qmPZ8ePHC1ynqHWWprp168rPz8+pLe934/777893bVHesuvH1KtXLy1fvlzNmzfXM888ow4dOqh169aqWrVqKVcPuB7hB6ggCvpjXqlSpVsuyws1586dk2EYOnbsmMaPH3/T/Vy6dOmWtaSnp8tmszkd8SiI3W6XJN15550FLs9bP6/f9Qob0/Wh5JVXXlFoaKhmz56tqVOnasqUKapUqZKio6M1ffp0x4XOtzJ16lS98sorqlatmjp16qS7777bcRRkxowZyszMLHC9otZZmm73d0OSnnrqKa1cuVLTpk3TnDlz9Ne//lU2m03t2rXT1KlTXX6dElCaCD8AJP3/P4IPPvigvvvuu9vaVkhIiAzD0H//+1/dddddt9xnQd8skqS0tDSnfiVhs9k0cOBADRw4UGfOnNFXX32lTz/9VMnJyTp48KB++OEHeXp6FrqNnJwcvfXWW6pRo4Z2796tsLAwxzLDMPTuu++WuD530r17d8cpu61bt2r58uVasGCBfve73+nAgQMKCQkxu0SgSLjmB4Cka9cINWzYUPv377/t0zEPPfSQJGnt2rWF9gsKClJkZKR++eUXHTt2LN/yvK+Zu+qoQmhoqGJiYrR48WK1b99e+/bt0y+//CJJjgBU0NGY06dPKz09XS1atHAKPpL03XffFfj1+uIqbP/lTWBgoH73u99p7ty5iouL04kTJ7R9+3azywKKjPADwOGll17S5cuXNWjQoAJPb6WmphbpOU1DhgyRp6enXnvtNR05csRpmWEYTteS9O/fX9nZ2RozZowMw3C0//DDD0pMTFRwcLDTV8+La+PGjU7bla6dzjl79qwkqXLlypKkO+64QzabTUePHs23jbCwMPn6+mrXrl1Od9g+d+6c/vjHP5a4tutVqVJFkgrcf3mwefPmAoNZ3j2O8uYRcAec9gLg8Pzzz+ubb77RwoULtXXrVj366KOqWbOmTpw4oQMHDmj79u365JNPbvkYhfvuu08zZszQSy+9pMaNGysmJkbh4eFKS0vT5s2bFR0drRkzZkiSRo8erS+++EIff/yx9u/frw4dOujkyZNavHixcnJyNG/ePAUGBpZ4TDExMQoKClLz5s0VHh6u7Oxsffnll9q3b59+//vfKzw8XNK1b0T99re/1ebNmxUbG6u6devKw8NDsbGxCg8P14svvqipU6eqadOmevzxx2W327V69WqFh4c7fXutpFq0aCFfX1/NmDFD586dU7Vq1SRJr7322m1v2xVeeuklHT9+XK1atVJERIRsNpu2bNmiHTt2qHnz5o77NgHugPADwCHvTtGPPfaY5s2bp1WrVunixYsKCwtT3bp1NWXKFD366KNF2tbQoUPVpEkTTZ06VatXr3Zs5+GHH9bTTz/t6Fe5cmWtX79ekydP1uLFizV9+nT5+fmpTZs2Gjt27G3/UZ04caLWrFmjHTt26PPPP5e/v7/q1Kmj2bNn69lnn3Xq+/HHH2v48OFatWqV0tPTZRiGWrVqpfDwcE2cOFFVqlRRYmKi3n//fd15553q3bu3xo0bpyZNmtxWjdK1Iz9Lly7VuHHjNG/ePMeptPISfsaMGaPly5dr586dSklJkZeXlyIiIjR58mS9+OKLt7xuCihPbMaNx4MBAG4jLi5OCxcuVGpqarl5sGme8lwbrI1rfgCgAqhdu7ZsNpvmzJljdimqXr26bDabFi5caHYpQIE47QUAbiwmJsbpqEpUVJR5xfyfV155RRcvXnS85yvwKG847QUAACyF014AAMBSCD8AAMBSCD8AAMBSCD8AAMBSCD8AAMBSCD8AAMBSCD8AAMBSCD8AAMBSCD8AAMBS/h+5Qog745y6AQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### PLOT OF THE TIME CONSTANTS (INITIALIZATION)\n",
    "fig, ax = plt.subplots( )\n",
    "for n in range(len(net_params)):\n",
    "    if len(net_params[n][1].shape)>0:\n",
    "        _ = ax.hist(-args.timestep/ np.log(net_params[n][1]), 25, alpha=0.75, label='Layer '+str(n+1))\n",
    "ax.set_xlabel( 'Time constant [ms]', size=14 )\n",
    "ax.set_ylabel( 'PDF', size=14 )\n",
    "ax.tick_params( labelsize=14 )\n",
    "ax.legend( prop={'size':12} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: train (128, 100, 700) - test (128, 100, 700)\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def predict(args_in, X):\n",
    "    \"\"\" Scans over time and return predictions. \"\"\"\n",
    "    # net_params, net_states, key, dropout_rate = args_in\n",
    "    _, net_states_hist = scan(model, args_in, X, length=args.nb_steps)\n",
    "    return net_states_hist\n",
    "# vmap the forward of the model\n",
    "v_predict = vmap(predict, in_axes=(None, 0))\n",
    "\n",
    "def one_hot(x, n_class):\n",
    "    return jnp.array(x[:, None] == jnp.arange(n_class), dtype=jnp.float32)\n",
    "\n",
    "def loss(key, net_params, net_states, X, Y, epoch, dropout_rate=0.):\n",
    "    \"\"\" Calculates CE loss after predictions. \"\"\"\n",
    "\n",
    "    # we might want to add noise in the forward pass --> memristor-aware-training\n",
    "    # weight = [net_params[i][0] for i in range( len(net_params) )]\n",
    "    # weight = cond(\n",
    "    #     epoch >= noise_start_step, \n",
    "    #     lambda weight, key : add_noise(weight, key, noise_std),\n",
    "    #     lambda weight, key : weight,\n",
    "    #     weight, key\n",
    "    # )\n",
    "    # forward pass\n",
    "    # net_states_hist = v_predict( [net_params, net_states, key, dropout_rate], X)\n",
    "    # Forward pass throught the whole model\n",
    "    args_in = [net_params, net_states, key, dropout_rate]\n",
    "    output_layer, out_spike_net = hsnn( args_in, X )\n",
    "    Yhat = decoder_cum( output_layer )\n",
    "\n",
    "    # compute the loss and correct examples\n",
    "    num_correct = jnp.sum(jnp.equal(jnp.argmax(Yhat, 1), jnp.argmax(Y, 1)))\n",
    "    # cross entropy loss\n",
    "    loss_ce = -jnp.mean( jnp.sum(Y * jnp.log(Yhat+1e-12), axis=-1) )\n",
    "    # L2 norm\n",
    "    loss_l2 = optimizers.l2_norm( net_params ) * args.l2_lambda\n",
    "    # firing rate loss\n",
    "    avg_spikes_neuron = jnp.mean( jnp.stack( [ jnp.mean( jnp.sum( out_spike_net[l], axis=1 ), axis=(0,-1) ) for l in range( len(net_params)-1 )] ) )\n",
    "    loss_fr = args.freq_lambda * (args.target_fr - avg_spikes_neuron)**2\n",
    "    loss_total = loss_ce + loss_l2 + loss_fr\n",
    "    loss_values = [num_correct, loss_ce]\n",
    "    return loss_total, loss_values\n",
    "\n",
    "# initialize parameters\n",
    "dropout_rate = 0.0\n",
    "args.seed = 14\n",
    "args.distrib_tau = True\n",
    "args.hierarchy_tau = False\n",
    "args.recurrent = False\n",
    "args.normalizer = 'batch' #'layer'\n",
    "args.norm_bias_init = 0.\n",
    "args.tau_mem = 0.2 #0.1\n",
    "args.l2_lambda = 0.\n",
    "args.freq_lambda = 0.\n",
    "if args.recurrent:\n",
    "    layer = rlif_step\n",
    "    model = hrsnn_step\n",
    "    args.w_scale = [0.075, 0.05]\n",
    "else:\n",
    "    layer = lif_step\n",
    "    model = hsnn_step\n",
    "    args.w_scale = [1/np.sqrt( args.n_in )] + [1/np.sqrt( args.n_hid )]*(args.n_layers-1)\n",
    "norm = BatchNorm\n",
    "args.n_layers = 3\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(seed=args.seed)\n",
    "# load data\n",
    "x_train, Y = next(iter( train_loader_custom_collate ))\n",
    "x_test, Y_test = next(iter( test_loader_custom_collate ))\n",
    "print('Input shape: train '+ str(x_train.shape) + ' - test '+ str(x_test.shape) )\n",
    "\n",
    "net_params, net_states = params_initializer( key, args )\n",
    "\n",
    "# import pickle\n",
    "# # params from sparch\n",
    "# params = pickle.load( open( '/Users/filippomoro/Desktop/params_snn_84p_numpy.pkl', 'rb' ) )\n",
    "# for i in range( len(net_params) ):\n",
    "#     if args.normalizer in ['batch', 'layer']:\n",
    "#         net_params[i][0][0] = params[f'snn.{i}.W.weight'].T\n",
    "#         net_params[i][1] = params[f'alpha{i}']\n",
    "#         net_params[i][0][1] = params[f'scale{i}']\n",
    "#         net_params[i][0][2] = params[f'bias{i}']\n",
    "#     else:\n",
    "#         net_params[i][0] = params[f'snn.{i}.W.weight'].T\n",
    "#         net_params[i][1] = params[f'alpha{i}']\n",
    "\n",
    "\n",
    "dropout_rate = 0.0\n",
    "# # testing the training function\n",
    "# args_ins = [net_params, net_states, key, dropout_rate]\n",
    "# args_out = scan(model, args_ins, x_train[0], length=args.nb_steps)\n",
    "# [net_params_hist, net_states_hist] = args_out\n",
    "\n",
    "args_in = [net_params, net_states, key, dropout_rate]\n",
    "output_layer, out_spike_net = hsnn( args_in, x_test )\n",
    "Yhat = decoder_cum( output_layer )\n",
    "\n",
    "# decoder\n",
    "# Yhat = jax.nn.softmax( jnp.mean( out_v_mem, axis=1 ), axis=-1 )\n",
    "# Yhat_vmax = jax.nn.softmax( jnp.max( out_v_mem, axis=1 ), axis=-1 )\n",
    "# Yhat_cum = jnp.mean( jax.nn.softmax( out_v_mem, axis=-1 ), axis=1)\n",
    "# print( Yhat_cum.shape )\n",
    "\n",
    "# loss\n",
    "loss_total, loss_values = loss(key, net_params, net_states, x_test, one_hot(Y, 20), 0)\n",
    "\n",
    "# values and gradients\n",
    "value, grads = value_and_grad(loss, has_aux=True, argnums=(1))(key, net_params, net_states, x_test, one_hot(Y_test,20), 0, dropout_rate=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = len( net_params )\n",
    "# collection of output spikes\n",
    "out_spike_net_b = []\n",
    "# Loop over the layers\n",
    "for l in range(n_layers):\n",
    "    if l == 0: layer_input_spike = x_test\n",
    "    else: layer_input_spike = out_spikes_layer\n",
    "    # making layers' params and states explitic\n",
    "    # parameters (weights and alpha) and the state of the neurons (spikes, inputs and membrane, ecc..)\n",
    "    w, alpha = net_params[l]; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states[l]\n",
    "    if len(w) == 3: # it means that we'll do normalization\n",
    "        weight, scale, bias = w\n",
    "    else: weight = w\n",
    "    if len(weight) ==2: weight, _ = weight\n",
    "    # we evolve the state of the neuron according to the LIF formula, Euler approximation\n",
    "    I_in = jnp.matmul(layer_input_spike, weight)\n",
    "    # Normalization (if selected)\n",
    "    if len(w) == 3: # it means that we'll do normalization\n",
    "        b, t, n = I_in.shape\n",
    "        I_in = norm( I_in.reshape( b*t, n ), bias = bias, scale = scale )\n",
    "        I_in = I_in.reshape( b,t,n ) # normalized input current\n",
    "    # Forward pass of the Layer\n",
    "    args_in_layer = [net_params[l], net_states[l]]\n",
    "    if l+1 == n_layers:\n",
    "        _, out_spikes_layer_b = vscan_layer_out( args_in_layer, I_in )\n",
    "    else: \n",
    "        _, out_spikes_layer = vscan_layer( args_in_layer, I_in )\n",
    "        # Dropout\n",
    "        key, key_dropout = jax.random.split(key, 2)\n",
    "        out_spikes_layer = dropout( key_dropout, out_spikes_layer, rate=dropout_rate, deterministic=False )\n",
    "    out_spike_net_b.append(out_spikes_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([5.504156 , 4.0522785, 4.3228045, 3.975809 , 6.000391 , 4.9515777,\n",
       "       5.8372865, 3.746243 , 7.292494 , 4.624026 , 4.171534 , 3.8599901,\n",
       "       4.6428614, 4.632159 , 6.5391397, 3.7971606, 4.2611313, 6.2887297,\n",
       "       6.3179307, 5.1822915], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sum( jax.nn.softmax( out_spikes_layer_b, axis=-1 ), axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([5.504156 , 4.0522785, 4.3228045, 3.975809 , 6.000391 , 4.9515777,\n",
       "       5.8372865, 3.746243 , 7.292494 , 4.624026 , 4.171534 , 3.8599901,\n",
       "       4.6428614, 4.632159 , 6.5391397, 3.7971606, 4.2611313, 6.2887297,\n",
       "       6.3179307, 5.1822915], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sum( jax.nn.softmax( out_spike_net[-1], axis=-1 ), axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0., dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.abs((out_spike_net[0] - out_spike_net_b[0])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.00076735, 0.00063383, 0.00097814, 0.00055645, 0.00085246,\n",
       "       0.0014552 , 0.00066718, 0.00067719, 0.00068003, 0.00044435,\n",
       "       0.00061735, 0.00170687, 0.00038253, 0.00085462, 0.00051275,\n",
       "       0.0007672 , 0.00067573, 0.00058511, 0.00051962, 0.00108186,\n",
       "       0.00147061, 0.0004725 , 0.00052765, 0.00142009, 0.00051044,\n",
       "       0.00079603, 0.00064606, 0.00085672, 0.0009251 , 0.00119561,\n",
       "       0.00057692, 0.0008034 , 0.00087499, 0.00061073, 0.00051732,\n",
       "       0.00054059, 0.00089255, 0.0019822 , 0.00101193, 0.00083508,\n",
       "       0.00071766, 0.00097441, 0.00071568, 0.00154482, 0.0008174 ,\n",
       "       0.00122004, 0.00086639, 0.00077438, 0.00132074, 0.00054285,\n",
       "       0.0019906 , 0.00095774, 0.00078799, 0.00099906, 0.00048988,\n",
       "       0.00050438, 0.00072055, 0.00095875, 0.00040959, 0.0004717 ,\n",
       "       0.00125962, 0.00110288, 0.00102205, 0.00089684, 0.00055581,\n",
       "       0.00066929, 0.00043818, 0.00068625, 0.00086503, 0.00119484,\n",
       "       0.00120707, 0.00050963, 0.00056746, 0.00061006, 0.00119519,\n",
       "       0.00122961, 0.00184453, 0.00064832, 0.00046168, 0.00042174,\n",
       "       0.00106348, 0.00084773, 0.00039816, 0.000551  , 0.00055351,\n",
       "       0.00063925, 0.00042804, 0.00065324, 0.00088577, 0.00047383,\n",
       "       0.00111541, 0.0006287 , 0.00097624, 0.00116362, 0.00066509,\n",
       "       0.00110988, 0.000816  , 0.00096251, 0.00067398, 0.00079679,\n",
       "       0.00049727, 0.00105399, 0.00092978, 0.00095503, 0.00051205,\n",
       "       0.00054026, 0.00130196, 0.00048317, 0.00101844, 0.0015346 ,\n",
       "       0.00079023, 0.0006019 , 0.0011287 , 0.00126398, 0.00101761,\n",
       "       0.00059772, 0.0006272 , 0.00040939, 0.00061192, 0.00042248,\n",
       "       0.00074097, 0.00049792, 0.00056987, 0.00097408, 0.00061671,\n",
       "       0.00043253, 0.00160346, 0.00118141], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the Gradients on the first layer\n",
    "\n",
    "net_params, net_states = params_initializer( key, args )\n",
    "\n",
    "# import pickle\n",
    "# # params from sparch\n",
    "# params = pickle.load( open( '/Users/filippomoro/Desktop/params_snn_84p_numpy.pkl', 'rb' ) )\n",
    "# for i in range( len(net_params) ):\n",
    "#     if args.normalizer in ['batch', 'layer']:\n",
    "#         net_params[i][0][0] = params[f'snn.{i}.W.weight'].T\n",
    "#         net_params[i][1] = params[f'alpha{i}']\n",
    "#         net_params[i][0][1] = params[f'scale{i}']\n",
    "#         net_params[i][0][2] = params[f'bias{i}']\n",
    "#     else:\n",
    "#         net_params[i][0] = params[f'snn.{i}.W.weight'].T\n",
    "#         net_params[i][1] = params[f'alpha{i}']\n",
    "\n",
    "### Computing the first pre-activation with Normalization\n",
    "def first_layer(net_params, x_test):\n",
    "    l = 0; layer_input_spike = x_test\n",
    "    w, alpha = net_params[l]; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states[l]\n",
    "    if len(w) == 3: # it means that we'll do normalization\n",
    "        weight, scale, bias = w\n",
    "    else: weight = w\n",
    "    if len(weight) ==2: weight, _ = weight\n",
    "    # we evolve the state of the neuron according to the LIF formula, Euler approximation\n",
    "    I_in = jnp.matmul(layer_input_spike, weight)\n",
    "    # Normalization (if selected)\n",
    "    if len(w) == 3: # it means that we'll do normalization\n",
    "        b, t, n = I_in.shape\n",
    "        I_in = norm( I_in.reshape( b*t, n ), bias = bias, scale = scale )\n",
    "        I_in = I_in.reshape( b,t,n ) # normalized input current\n",
    "\n",
    "    # Forward pass of the Layer\n",
    "    args_in = [net_params[l], net_states[l]]\n",
    "    if l+1 == len( net_params ):\n",
    "        _, out_spikes_layer = vscan_layer_out( args_in, I_in )\n",
    "    else: \n",
    "        _, out_spikes_layer = vscan_layer( args_in, I_in )\n",
    "    \n",
    "    return jnp.mean( out_spikes_layer**2 ), out_spikes_layer\n",
    "\n",
    "value, grads = value_and_grad(first_layer, has_aux=True, argnums=(0))(net_params, x_test)\n",
    "grads[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1841., 1496., 2706., 1425., 2120., 2726., 1357., 1732., 1748.,\n",
       "        953., 1390., 3005., 1022., 2497., 1392., 1752., 1696., 1624.,\n",
       "       1417., 2558., 2813., 1110.,  959., 2756., 1091., 1636., 1732.,\n",
       "       1980., 2398., 2893., 1690., 1910., 2477., 1821., 1074., 1314.,\n",
       "       2111., 3304., 2774., 2132., 1812., 2450., 1778., 2923., 1949.,\n",
       "       2931., 1886., 1918., 2632.,  949., 3343., 2409., 1899., 2852.,\n",
       "        896.,  845., 1640., 2166., 1171., 1121., 2551., 2628., 2515.,\n",
       "       2086., 1265., 1340., 1109., 1677., 2206., 2536., 2456., 1100.,\n",
       "       1318., 1265., 2435., 3011., 3183., 1580., 1272., 1162., 2368.,\n",
       "       2050., 1266., 1533., 1144., 1218.,  905., 1792., 2072.,  928.,\n",
       "       2536., 1447., 2435., 2476., 1437., 2704., 1748., 2179., 1948.,\n",
       "       1821., 1275., 2312., 2279., 2255., 1564., 1096., 2554., 1251.,\n",
       "       2442., 2916., 1831., 1168., 2754., 2865., 2289., 1210., 1598.,\n",
       "        970., 1499.,  931., 1574.,  931., 1896., 2230., 1221., 1070.,\n",
       "       2989., 2451.], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value[1].sum(axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.00093607, 0.00145668, 0.00127759, 0.00121363, 0.00093815,\n",
       "       0.00098057, 0.00073845, 0.00119019, 0.00096742, 0.00076319,\n",
       "       0.00214508, 0.00073202, 0.00170945, 0.0015956 , 0.0009381 ,\n",
       "       0.00140231, 0.00111321, 0.00095307, 0.00111712, 0.00151042,\n",
       "       0.00124079, 0.00082157, 0.00099836, 0.00160323, 0.00137172,\n",
       "       0.00084297, 0.00186251, 0.00120335, 0.00135386, 0.00111624,\n",
       "       0.00087388, 0.00243268, 0.00147205, 0.0010989 , 0.00081691,\n",
       "       0.00289969, 0.00126891, 0.00138916, 0.0008288 , 0.00120576,\n",
       "       0.00174194, 0.00084663, 0.00074009, 0.00115459, 0.00111908,\n",
       "       0.00105559, 0.00084274, 0.00148386, 0.00147913, 0.00218714,\n",
       "       0.00102801, 0.00090773, 0.00187288, 0.00106426, 0.00094484,\n",
       "       0.00114213, 0.00137229, 0.00105295, 0.0005389 , 0.00134609,\n",
       "       0.00190055, 0.00138249, 0.00116696, 0.00104026, 0.00163596,\n",
       "       0.00164523, 0.00102256, 0.00107317, 0.00094486, 0.00076259,\n",
       "       0.0013805 , 0.00142811, 0.00223596, 0.00122479, 0.00091672,\n",
       "       0.00073852, 0.00125184, 0.00092384, 0.00173778, 0.00083167,\n",
       "       0.00180273, 0.00250651, 0.00097001, 0.00080801, 0.00111075,\n",
       "       0.001258  , 0.00157741, 0.00245218, 0.00100034, 0.00119354,\n",
       "       0.00187821, 0.00171486, 0.00113027, 0.00124067, 0.00120531,\n",
       "       0.0010548 , 0.00210811, 0.0008066 , 0.00185732, 0.00104689,\n",
       "       0.00121499, 0.00092767, 0.00225472, 0.00159579, 0.00107744,\n",
       "       0.00253347, 0.00184975, 0.00070645, 0.00112272, 0.0014731 ,\n",
       "       0.00097   , 0.00206663, 0.00148232, 0.00207957, 0.0014951 ,\n",
       "       0.00164243, 0.00123348, 0.0013655 , 0.00122924, 0.00090355,\n",
       "       0.00197572, 0.00114443, 0.00084005, 0.0010181 , 0.00091262,\n",
       "       0.00100579, 0.00129661, 0.00107829], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Computing the first pre-activation with Normalization\n",
    "def second_layer(net_params, x_test):\n",
    "    l = 1; layer_input_spike = x_test\n",
    "    w, alpha = net_params[l]; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states[l]\n",
    "    if len(w) == 3: # it means that we'll do normalization\n",
    "        weight, scale, bias = w\n",
    "    else: weight = w\n",
    "    if len(weight) ==2: weight, _ = weight\n",
    "    # we evolve the state of the neuron according to the LIF formula, Euler approximation\n",
    "    I_in = jnp.matmul(layer_input_spike, weight)\n",
    "    # Normalization (if selected)\n",
    "    if len(w) == 3: # it means that we'll do normalization\n",
    "        b, t, n = I_in.shape\n",
    "        I_in = norm( I_in.reshape( b*t, n ), bias = bias, scale = scale )\n",
    "        I_in = I_in.reshape( b,t,n ) # normalized input current\n",
    "\n",
    "    # Forward pass of the Layer\n",
    "    args_in = [net_params[l], net_states[l]]\n",
    "    if l+1 == len( net_params ):\n",
    "        _, out_spikes_layer = vscan_layer_out( args_in, I_in )\n",
    "    else: \n",
    "        _, out_spikes_layer = vscan_layer( args_in, I_in )\n",
    "    \n",
    "    return jnp.mean( out_spikes_layer**2 ), out_spikes_layer\n",
    "\n",
    "value_2nd, grads = value_and_grad(second_layer, has_aux=True, argnums=(0))(net_params, value[1])\n",
    "grads[1][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([2116., 2220., 2376., 1787., 1938., 1718., 1257., 1908., 1875.,\n",
       "       1438., 2966., 1459., 2365., 2282., 1834., 2176., 2831., 2052.,\n",
       "       1784., 2298., 1793., 1383., 1786., 2319., 2028., 1470., 2583.,\n",
       "       2368., 1924., 1704., 1471., 3168., 2155., 2795., 1932., 3759.,\n",
       "       1910., 2476., 1639., 2347., 2957., 1343., 1618., 2535., 1627.,\n",
       "       2158., 1491., 2475., 2125., 2979., 1687., 1501., 3221., 1932.,\n",
       "       1550., 1884., 2080., 2873., 1609., 2739., 2612., 1998., 2555.,\n",
       "       2578., 2408., 2363., 1658., 2576., 1815., 1690., 1896., 2067.,\n",
       "       2980., 2681., 1774., 1609., 2312., 1427., 2476., 2506., 3028.,\n",
       "       3379., 3098., 1640., 2076., 1857., 2226., 3291., 2395., 2394.,\n",
       "       2713., 2514., 1985., 3354., 1962., 2630., 2891., 1583., 2596.,\n",
       "       2099., 1882., 1678., 3212., 2348., 2058., 3390., 2587., 1543.,\n",
       "       2175., 2180., 2160., 2896., 2110., 2814., 2189., 2299., 2701.,\n",
       "       1948., 1816., 1769., 2775., 2811., 1737., 2478., 1398., 2069.,\n",
       "       2833., 1966.], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_2nd[1].sum( axis=(0,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.00517766,  0.01526389,  0.01000238,  0.1457658 ,  0.09596697,\n",
       "        0.0159039 , -0.00985695,  0.04546271,  0.02727821,  0.01400958,\n",
       "        0.01759365, -0.01035395,  0.01177882,  0.03090918,  0.00503275,\n",
       "        0.02642335,  0.01599982,  0.03837876,  0.03031916,  0.0291216 ],      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Computing the first pre-activation with Normalization\n",
    "def third_layer(net_params, x_test):\n",
    "    l = 2; layer_input_spike = x_test\n",
    "    w, alpha = net_params[l]; w_mask, tau, V_mem, out_spikes, v_thr, noise_sd = net_states[l]\n",
    "    if len(w) == 3: # it means that we'll do normalization\n",
    "        weight, scale, bias = w\n",
    "    else: weight = w\n",
    "    if len(weight) ==2: weight, _ = weight\n",
    "    # we evolve the state of the neuron according to the LIF formula, Euler approximation\n",
    "    I_in = jnp.matmul(layer_input_spike, weight)\n",
    "    # Normalization (if selected)\n",
    "    if len(w) == 3: # it means that we'll do normalization\n",
    "        b, t, n = I_in.shape\n",
    "        I_in = norm( I_in.reshape( b*t, n ), bias = bias, scale = scale )\n",
    "        I_in = I_in.reshape( b,t,n ) # normalized input current\n",
    "\n",
    "    # Forward pass of the Layer\n",
    "    args_in = [net_params[l], net_states[l]]\n",
    "    if l+1 == len( net_params ):\n",
    "        _, out_spikes_layer = vscan_layer_out( args_in, I_in )\n",
    "        out_spikes_layer = jnp.sum( jax.nn.softmax( out_spikes_layer, axis=-1 ), axis=1)\n",
    "    else: \n",
    "        _, out_spikes_layer = vscan_layer( args_in, I_in )\n",
    "    \n",
    "    return jnp.mean( out_spikes_layer**2 ), out_spikes_layer\n",
    "\n",
    "value_3rd, grads = value_and_grad(third_layer, has_aux=True, argnums=(0))(net_params, value_2nd[1])\n",
    "grads[2][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([4.0918617, 6.176214 , 6.649568 , 4.9560757, 5.0084147, 4.631906 ,\n",
       "       4.8350964, 3.8296063, 4.014703 , 6.277969 , 6.2531676, 4.3820057,\n",
       "       4.766175 , 4.4839563, 5.495924 , 4.823924 , 3.942988 , 6.9296145,\n",
       "       4.6212134, 3.8296063], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_3rd[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.7723984e-06 0.021833293\n",
      "-0.00047378277 0.050812863\n",
      "0.0007956222 0.05092877\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range( args.n_layers ):\n",
    "    print( net_params[i][0][0].mean(), net_params[i][0][0].std() )\n",
    "\n",
    "_ = plt.hist( grads[2][0][0].flatten(), 50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.14742431, dtype=float32), Array(0.16816773, dtype=float32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.mean( out_spike_net[0], axis=(0,1,2) ), jnp.mean( out_spike_net[1], axis=(0,1,2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x30bd993c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( out_spike_net[2][0].T )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.train_alpha = True\n",
    "args.hierarchy_tau = False\n",
    "args.distrib_tau = True\n",
    "args.distrib_tau_bittar = False\n",
    "args.recurrent = False\n",
    "args.normalizer = 'batch' # 'batch' #'layer'\n",
    "args.norm_bias_init = 0.0\n",
    "if args.normalizer == 'batch': norm = BatchNorm\n",
    "elif args.normalizer == 'layer': norm = LayerNorm\n",
    "else: norm = None\n",
    "# network architecture\n",
    "if args.recurrent: \n",
    "    model = hrsnn_step\n",
    "    layer = rlif_step\n",
    "else: \n",
    "    model = hsnn_step\n",
    "    layer = lif_step\n",
    "layer_out = li_step\n",
    "args.n_layers = 4\n",
    "args.n_hid = 128\n",
    "# time constants\n",
    "args.tau_mem = 0.1 #0.1\n",
    "delta_tau = 0.1\n",
    "args.tau_end = args.tau_mem + delta_tau\n",
    "args.tau_start = args.tau_mem - delta_tau\n",
    "args.distrib_tau_sd = 0.2\n",
    "if args.recurrent: args.tau_out = 0.1\n",
    "else: args.tau_out = 0.2 #0.014*5 # 0.21 #0.01\n",
    "# weight init\n",
    "### 0.3 for FF, 0.1 for Rec\n",
    "if args.recurrent: args.w_scale = [0.075, 0.05] #[[3*np.sqrt(1/args.n_in), 2*np.sqrt(1/args.n_hid)], [2*np.sqrt(1/args.n_hid), 2*np.sqrt(1/args.n_hid)], [2*np.sqrt(1/args.n_hid), 2*np.sqrt(1/args.n_hid)] ] #[0.075, 0.05]\n",
    "else : args.w_scale = [ 1*np.sqrt(1/args.n_in), 1*np.sqrt(1/args.n_hid), 1*np.sqrt(1/args.n_hid) ] #[0.3]*args.n_layers\n",
    "# LR and regularizers\n",
    "if args.recurrent: args.lr = 0.01\n",
    "else: args.lr = 0.01\n",
    "args.lr_decay = 0.5\n",
    "args.lr_decay_every = 50\n",
    "args.l2_lambda = 0 #1e-6\n",
    "args.freq_lambda = 0 #1e-6\n",
    "args.dropout_rate = 0.1\n",
    "n_epochs = 20\n",
    "\n",
    "train_loss, test_acc_shd, val_acc_shd, net_params_trained = train_hsnn(key = jax.random.PRNGKey(args.seed), n_epochs=n_epochs, args = args, \n",
    "                                                            train_dl = train_loader_custom_collate, test_dl = test_loader_custom_collate, val_dl=val_loader_custom_collate,\n",
    "                                                            param_initializer=params_initializer,\n",
    "                                                            noise_start_step=10, noise_std=0.1, dataset_name='shd', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(args.n_layers-1):\n",
    "    _ = plt.hist( net_params_trained[i][1], 25, alpha=0.6, label=f'Layer {i}' )\n",
    "    print( np.mean(  net_params_trained[i][1] ) )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
